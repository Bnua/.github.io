<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[“AARRR”与“上瘾模型”]]></title>
    <url>%2F2019%2F04%2F05%2F1%2F</url>
    <content type="text"><![CDATA[《上瘾》和《增长黑客》分别提出了两种模型“上瘾模型“和“AARRR模型”，从表面来看两个模型的侧重点不同，“上瘾模型”是可以让用户对产品形成使用习惯，不知不觉依赖上。“AARRR”更加侧重在让用户裂变增长。在我读完有关这两个模型的几本书后，两种模型就是互相的理解重构(当我的文章写到一半的时候，对这个观点产生了自我怀疑)。从结果来看，他们的目的都是：更高的商业价值，更快速的用户增长。从方法来看，上瘾模型分为四个部分，“AARRR”模型有五个部分。在之前有写过，《上瘾》的读书笔记。所以首先对”AARRR”进行简单的介绍：根据不同阶段用户参与行为的深度和类型，我们可以将增长目标拆分并概括为“AARRR”转化漏洞模型： Acquisition（获取用户）：指让潜在用户首次接触到产品，或者可以更宽泛地理解为“吸引流量”、“用户量增长。 Activation（激发活跃）：获取到用户后下一步是引导用户完成某些“指定动作”，使之成为长期活跃的忠实用户。这里的“指定动作”可以是填写一份表单、下载一个软件、发表一篇内容、上传一张照片，或是任何促使他们正确而高效使用产品的行为。 Retention（提高留存）：在解决了用户的活跃度问题后，另一个问题又冒了出来。用户来得快，走得也快。产品缺乏黏性，导致的结果是，一方面新用户不断涌入，另一方面他们又迅速流失。因此提高用户留存，是维持产品价值、延长生命周期的重要手段。 Revenue（增加收入）：商业主体都是逐利的，很少有人创业只是纯粹出于兴趣，绝大多数创业者最关心的就是收入。即使是互联网时代的免费产品，也应该有其盈利模式。 Referral（病毒传播）：社交网络的兴起促成了基于用户关系的病毒传播，这是低成本推广产品的全新方式，运用妥当将可能引发奇妙的链式增长。我们对”AARRR”模型进行解释说明后，对比《上瘾》我们会发现，这些方法都是相似的，接下来，我们把他们结合起来进行再一次的重构解读。 获取用户-触发上瘾中的触发分为内部触发和外部触发，两个触发模式都是 AARRR 中的 Acquisition。如何获取用户？获取用户的方式?方法总结如下： 广告，搜索引擎做推广 应用商店，正面的媒体报道 通过社交软件：qq，微信，微博等 地推，饥饿营销等 《增长黑客》一书中有大量的实际例子来说明这些获取用户的方法。上瘾模型中还特意说了内部触发。当某个产品与你的思想、情感或是原本已有的常规活动发生密切关联时，那一定是内部触发在起作用。外部触发会借助闹钟或是大号的按钮这一类感官刺激来影响用户，内部触发则不同，你看不见，摸不着，也听不到，但它会自动出现在你的脑海中。所以说，将内部触发嵌入产品，是消费者技术成功的关键。 激发活跃-行动两种模型分别用两个概念说了这个问题。总结一下就是在获取用户后，如何让用户频繁和产品产生交互行为。也就是激发活跃和行动。我们为何要采取行动？要使人们完全行动起来必须有三个要素：充分的动机，完成这个行为的能力，促使人们付诸行动的触发。 充分的动机：能够驱使我们采取行动的核心动机不外乎三种。第一种，追求快乐，逃避痛苦；第二种，追求希望，逃避恐惧；第三种，追求认同，逃避排斥。 完成行为的能力：我们在设计产品的时候，一定要明白用户最缺乏什么，是什么阻碍了用户完成的活动，时间，精力，金钱，操作难度等等。 促使人们付诸行动的触发： 赠券效应：最暴力的方式，红包补贴，优惠券 稀缺原理：机会越少，价值越高 增加诱饵：某个功能有个诱饵选项，会提高用户的行为 提高留存-多变的酬赏在这部分。上瘾模型和AARRR模型的表述略有不同，一个是目的，一个是方法。我们可以设置多变的酬赏的去提高留存。所以在这里我们主要结合多变的酬赏来讲讲怎么提高留存？ 多变的酬赏人们使用某个产品，归根结底是因为这个产品能够满足他们的某种需要。在前文中我们说过，如果产品的操作步骤简单易行，那么人们会更乐意亲身一试。但是，要想让用户试过之后还念念不忘，那就要看产品是不是能满足用户的需求了。在人们赌博时，大脑中的哪个区域更加活跃。当赌博者获得酬赏时（在这个实验中，赢来的钱就是酬赏），伏隔核并没有受到刺激，相反，在他们期待酬赏的过程中，这个区域发生了明显的波动。这说明，驱使我们采取行动的，并不是酬赏本身，而是渴望酬赏时产生的那份迫切需要。大脑因为渴望而形成的紧张感会促使我们重复某个动作。何为“多变”？我们和小孩一样，如果能够预测到下一步会发生什么，就不会产生喜出望外的感觉。产品就像是孩子生活中的小狗，要想留住用户的心，层出不穷的新意必不可少。 用户流失的原因 存在程序漏洞，性能瓶颈 用户被频繁骚扰，这个骚扰有用户给用户带来的，也有产品给用户带来的 话题产品热度衰减 有更好的竞品 提高留存在上述分析用户流失原因的时候，有产品本身的因素，也有一些外来因素。我们着重说一下有什么方法可以提高用户对产品的粘性，上瘾模型的多变酬赏正是为我们提供了一些方法 社交酬赏：人们从产品中通过与他人的互动而获取的人际奖励。 自我酬赏：从产品中体验到的操控感、成就感和终结感。 猎物酬赏：人们从产品中获得的具体资源或信息。 增加收入-投入产品都是要以商业化盈利为目的，在写到这里的时候，我意识到，产品增加收入和用户投入的关系，是统一又矛盾的，我对刚开始准备写这篇文章的观点进行了怀疑。上瘾模型的投入是指用户对产品进行时间，精力，金钱等的付出。以致于让用户对产品的依赖性更强。而AARRR中的增加收入是产品找到一个合适的盈利点。所以这部分分为两部分来讲 投入用户对某件产品或某项服务投入的时间和精力越多，对该产品或服务就越重视。事实上，有充分证据表明，用户投入的多寡与其热爱某项事物的程度成正比。 增加收入免费经济大行其道，想想当年360一系列产品，和各种杀毒软件的PK，看看当前的APP，有几个是需要付费的？免费已经是互联网的通识，大家都靠免费策略来抢占市场。免费归免费，还是有其他盈利策略的： 基本功能免费，高级功能收费的Freemium 交叉补贴：通过有意识地以优惠甚至亏本的价格出售一种产品，从而达到促进销售另一种盈利的产品。 三方市场流量变现：投放广告 在增加收入这里，能做到的远远不止于此。 病毒传播病毒传播，也就是口碑传播，是通过热点话题、舆论导向等方式引导用户主动传播，吸引更多的用户，并且再次传播等方式。这是一种低成本的传播方式，每个参与者都是下一次传播的节点。 衡量病毒传播的2大指标： K因子:K Factor，用来评判病毒传播的覆盖面，感染率是指某个用户想其他人传播产品的程度，比如发一封邮件，一次口头推荐，一条微博，一条朋友圈等；转化率是指被感染用户转化成新用户的比例1个K 因子表示平均一个用户能带来一个新用户K因子越高，说明带来新用户的能力越强 病毒循环周期是指从用户发出病毒邀请，到新用户完成转化（如点击阅读、注册、消费行为）所花费的时间。周期越短越好传播手段 Bug营销Bug是指程序的漏洞，本不该出现的，但是通过故意制造一些漏洞，以此来进行传播，依靠用户“占便宜”的心理，可以获得快速的传播。 借势营销创造不了热点，学会借热点，也是一种好方法。借势就是借用当前的热点，沾沾流量，兴许会事半功倍。 构建产品外的病毒循环通过外部渠道来获得传播，比如社交应用微信、微博，比如有很多产品都会开发些小游戏、文案等通过公众号或者小程序的形式在微信中达到传播。这种传播主要的考验：创意来源、生命周期、产品契合度 产品内置的传播因子在产品内置一些传播手段，也是非常重要的，这就需要让用户区进行主动的推荐邀请，比如内置的分享到其他应用 用户心理想要达到病毒传播，需要深入思考用户，思考用户心理喜爱： 对于自己喜欢的东西，用户是愿意去主动传播的利益交换： 任何人都是“自私”的，“自利”的，通过邀请新人进行返利就是一种方式，为了获取更多的利益，就会主动去邀请更多的用户互惠： 互惠是逐利的一种变体，在邀请新用户的同时，两人可同时获取一定利益求助： 基于社交，这种方式一般小游戏中用的较多，比如生命值耗尽，可以通过向好友分享，获得新的机会炫耀： 每个人都渴望表现，获取别人的关注，比如支付宝年度账单，大V认证等稀缺：就像饥饿营销，比如通过邀请制才能获取部分体验 上瘾模型和AARRR模型是用户增长方面的书籍，在刚开始写这个文章的时候，是我刚看完《上瘾》，联想到了《增长黑客》，在总结的途中，我们可以看到两个模型的侧重点是有所不同。这两本书都值得推荐《上瘾》和《增长黑客》。有大量的案例来说明了理论，可以让我们更好的理解产品方法，当然有实际的产品开发经验可以联系自己的产品去印证学习。]]></content>
      <categories>
        <category>产品之路</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[《上瘾》学习笔记]]></title>
    <url>%2F2019%2F03%2F29%2F1%2F</url>
    <content type="text"><![CDATA[简介一旦成功地使用户对产品形成了使用习惯，企业就能获益匪浅，具体的变现在： 更高的用户终身价值 更大的价格灵活性 更快速的增长 更强的竞争优势 《上瘾》中总结了一套“上瘾模型”，可以让用户对产品连续循环，让用户不知不觉依赖上产品。 上瘾模式 触发: 促使做出某种举动的诱惑 行动: 对某种回报心怀期待的情况下做出的举动 多变的酬赏： 激发人们对某种事物的强烈渴望 投入： 提高用户以后再次进入上瘾循环的概率 思维导图]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[plotly高级图形-时间序列]]></title>
    <url>%2F2019%2F02%2F28%2F1%2F</url>
    <content type="text"><![CDATA[plotly时间序列Plotly 对时间序列的支持比较友好，既支持字符串格式，又支持日期/时间格式，而且使用起来相当简单。 时间序列：123456789101112131415161718import plotly as pyimport plotly.graph_objs as gofrom datetime import datetime# ----------pre defpyplt = py.offline.plot# ----------codex_datetime = [datetime(year=2013, month=10, day=4), datetime(year=2013, month=11, day=5), datetime(year=2013, month=12, day=6)]x_string = [&apos;2013-10-04&apos;, &apos;2013-11-05&apos;, &apos;2013-12-06&apos;]trace_datetime = go.Scatter(x=x_datetime, y=[1, 3, 6],name=&apos;trace_datetime&apos;)trace_string = go.Scatter(x=x_string, y=[2, 4, 7],name=&apos;trace_string&apos;)data = [trace_datetime, trace_string]pyplt(data, filename=&apos;timeSeries.html&apos;) 从代码中可以看出，只要传入的 x是日期或时间格式的字符串，Plotly 就会自动识别为时间格式。 时间范围约束：123456789101112131415161718192021222324252627282930313233import plotly as pyimport plotly.graph_objs as goimport datetime# ----------pre defpyplt = py.offline.plot# ----------codedef to_unix_time(dt): &apos;&apos;&apos; :param dt:datetime类型的时间戳 :return: dt相对于utc起始时间差别的毫秒数 &apos;&apos;&apos; epoch = datetime.datetime.utcfromtimestamp(0) # 获取0时刻对应的utc（世界标准时间） return (dt - epoch).total_seconds() * 1000 # 计算传入的时间相对于utc的起始时间差别多少毫秒x = [datetime.datetime(year=2013, month=10, day=4), datetime.datetime(year=2013, month=11, day=5), datetime.datetime(year=2013, month=12, day=6)]data = [go.Scatter( x=x, y=[1, 3, 6])]layout = go.Layout(xaxis = dict( range = [to_unix_time(datetime.datetime(2013, 10, 17)), to_unix_time(datetime.datetime(2013, 11, 20))] ))fig = go.Figure(data = data, layout = layout)pyplt(fig, filename=&apos;timeRange.html&apos;) 滑动选择控件Plotly 本身就是可以进行选择展出，滑动选择控件可以更直观的看出被圈出的范围。在这里我们对从本地用 pandas 加载了数据。 1234567891011121314151617181920212223242526272829303132333435363738394041424344import plotly as pyimport plotly.graph_objs as goimport pandas as pd# ----------pre defpyplt = py.offline.plot# ----------codedf = pd.read_csv(r&apos;day01.csv&apos;,index_col=[0])trace = go.Scatter(x=df.index, y=df.close)data = [trace]layout = dict( title=&apos;时间序列的滑块与选择器&apos;, xaxis=dict( rangeselector=dict( buttons=list([ dict(count=1, label=&apos;1m&apos;, step=&apos;month&apos;, stepmode=&apos;backward&apos;), dict(count=6, label=&apos;6m&apos;, step=&apos;month&apos;, stepmode=&apos;backward&apos;), dict(count=1, label=&apos;YTD&apos;,#今天以来 step=&apos;year&apos;, stepmode=&apos;todate&apos;), dict(count=1, label=&apos;1y&apos;, step=&apos;year&apos;, stepmode=&apos;backward&apos;), dict(step=&apos;all&apos;) ]) ), rangeslider=dict(), type=&apos;date&apos; ))fig = dict(data=data, layout=layout)pyplt(fig,filename=&apos;RangeSlide.html&apos;) 滑块与选择器主要是通过 Layout布局函数来实现的。对于选择器，主要在xais.rangeselector.buttons中定义一些参数。 xaxis=dict( rangeselector=dict( buttons=list([ dict(count=1, label=&apos;1m&apos;, step=&apos;month&apos;, stepmode=&apos;backward&apos;), dict(count=6, label=&apos;6m&apos;, step=&apos;month&apos;, stepmode=&apos;backward&apos;), dict(count=1, label=&apos;YTD&apos;,#今天以来 step=&apos;year&apos;, stepmode=&apos;todate&apos;), dict(count=1, label=&apos;1y&apos;, step=&apos;year&apos;, stepmode=&apos;backward&apos;), xaxis表示对x轴进行定义； rangeselector表示对x轴的选择器进行定义； buttons表示选择器的按钮，是一个列表形式，每个列表元素都是一个选择器按钮。 “count=1,step=’month’”表示这个选择器覆盖的时间长度是“1 ×month”，即一个月。“label=’1m’”表示选择器的标签为1m。 stepmode有以下两种使用方法: 当stepmode=’backward’时，表示从后往前推进count × step时间。例如，当count=1、step=’year’时，表示时间范围将近一年。 当 stepmode=’todate’时，一般只有一种用法，就是计算今年以来的时间。例如，当count=1、step=’year’时，表示时间范围从最后日期到最后日期所在的年初，而不是近一年。]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>plotly</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[plotly与pandas]]></title>
    <url>%2F2019%2F02%2F27%2F1%2F</url>
    <content type="text"><![CDATA[使用cufflinks绘图为了方便绘图，Plotly 为 Pandas 做了特殊的封装，这个封装模块就是 cufflinks。cufflinks 的作用是改变 Pandas 绘图的默认呈现方式。Pandas 绘图默认的呈现方式是 Matplotlib，cufflinks 把这种呈现方式改为 Plotly。 基础操作：使用cufflinks绘制线形图非常简单，与使用Pandas绘图并没有什么不同。cufflinks 并不影响 Pandas 的使用方式，只是在底层把 Pandas 绘图结果的呈现方式 Matplotlib 变为 Plotly，我们平时怎么使用 Pandas，现在还怎么使用 Pandas。一般情况下，使用 cufflinks 改变 Pandas 的绘图呈现方式需要做如下几个步骤的工作： 导入cufflinksimport cufflinks as cf 设置Pandas的输出模式cf.set_config_file(offline=True, theme=&#39;ggplot&#39;)cufflinks 已经为我们封装好了多种非常流行的主题，包括polar、pearl、henanigans、solar、ggplot、space和white等，可以通过cf.getThemes()方法获取当前版本所支持的所有主题。 绘制图形df.iplot(kind=&#39;scatter&#39;, filename=&#39;tmp/cf_line.html&#39;)cufflinks只支持 iplot 的绘图函数，不支持 plot 的绘图函数。 进阶操作通过 cufflinks 快速生成所需要的数据，在学习 Pandas 数据处理与绘图的过程中非常高效。这也是 plotly 的强大所在。cf.datagen 是 cufflinks 封装好的生成 Pandas 数据的模块，里面包含了常见的绘图（如bar、pie、scatter、ohlc）数据所需要的函数，我们可以通过dir(cf.datagen)命令查看可用的数据。在转载翻译的 python可视化神器-plotly 中 就是Plotly + cufflinks 的简单操作体现。]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>plotly</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[plotly基础图形-饼图]]></title>
    <url>%2F2019%2F02%2F26%2F1%2F</url>
    <content type="text"><![CDATA[plotly绘制饼图使用Plotly绘制饼图需要使用 graph_objs 中的 Pie 函数。Pie 函数中最常用的两个属性一个是 values，用于赋给其需要可视化的数据；另一个是 labels，表示不同数据对应的标签。 饼图：12345678910111213141516171819202122import plotly as pyimport plotly.graph_objs as gopyplt = py.offline.plotlabels = [&apos;上海国际集团有限公司&apos;, &apos;中国移动通信集团&apos;,\ &apos;富德生命人寿-传统&apos;, &apos;富德生命人寿-资本金&apos;, &apos;上海上国投资产管理有限公司&apos;]values = [4222533311, 4103763711, 2138028672, 1356332558, 1073516173]colors = [&apos;#104E8B&apos;, &apos;#1874CD&apos;, &apos;#1C86EE&apos;, &apos;#6495ED&apos;]trace = [go.Pie(labels = labels, values = values, rotation = 30, opacity = 1, showlegend = False, pull = [0.1,0,0,0,0], hoverinfo = &apos;label+percent&apos;, textinfo = &apos;percent&apos;, # textinfo = &apos;value&apos;, textfont = dict(size = 30, color = &apos;white&apos;), marker = dict(colors = colors, line = dict(color = &apos;#000000&apos;, width = 2)))]fig = go.Figure(data = trace)pyplt(trace, filename=&apos;styled_pie_chart.html&apos;) 参数解读 rotation 参数可以对饼图进行旋转，其取值为0～360。 opacity 参数用于设置透明度。 showlegend 参数是布尔类型，True 表示展示图例，False 表示隐藏图例。 pull参数用于设置组成饼图的各个扇形的突出程度，0表示不突出，本例中通过设置 pull 参数为[0,1,0,0,0,0]，使其中一个扇形突出。 textinfo 参数用于设置显示在扇形上的是具体数值（value）还是比例（percent）。 textfont参数用于设置所显示内容的样式，本例中设置了字体大小（size）和字体颜色（color）。 marker参数用于设置每个扇形的样式，其中colors用于设置颜色 line用于设置扇形边框的样式。 direction：饼图方向，有 clockwise（顺时针）和 counterclockwise（逆时针），默认值为 counterclockwise。 dlabel：饼图图标步进值，默认值为1。 domain：范围，设置各个扇区的大小。 hole：设置环形饼图内径孔的半径，范围是0～1，默认值为0，参数是与外径的比值。 label0：生成一组扇区图标的起点数字，默认值为0。 labels：每个扇区的图标字符串数组列表，一般用Pandas的时索引值。 legendgroup：图标参数，默认是空字符串。 name：名称参数。 pullsrc：各个扇区比例数组列表。 sort：布尔变量，扇区排序开关。 values：每个扇区的数值大小。]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>plotly</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[plotly基础图形-直方图]]></title>
    <url>%2F2019%2F02%2F25%2F1%2F</url>
    <content type="text"><![CDATA[plotly绘制直方图使用 Plotly 绘制直方图需要用到 graph_objs 包中的 Histogram 函数。将数据赋值给函数中的x变量，即x = data，即可绘制直方图；若将数据赋值给y变量，则绘制水平直方图。histnorm 是 Histogram 函数的另一个属性，默认状态下表示直方图的纵坐标落入区间内的样本数目；若设定histnorm = ‘probability’，则纵坐标变为落入区间内的样本频率。 基本直方图：1234567891011import plotly as pyimport plotly.graph_objs as goimport numpy as nppyplt = py.offline.plots1 = np.random.RandomState(1)x = s1.randn(1000)data = [go.Histogram(x=x, histnorm = &apos;probability&apos;)] # y = x 水平直方图，histnorm=&apos;probability&apos; y轴显示概率，没有则显示数目pyplt(data, filename=&apos;basic_histogram.html&apos;) 直方图补充 重叠直方图：需要在 Layout 中设置 barmode 属性，将其改为 ‘overlay’，如果不对其进行设置，会出现 Plotly 默认将两个直方图的柱形宽度强制变窄的情况，以满足重叠部分显的需求。与 Bar 函数等相同，Histogram 函数中也有 opacity 等通用属性。 层叠直方图：绘制层叠直方图同样需要设置 barmode 属性，将其设置为’stack’。 累积直方图：累积直方图是直方图的累积形式，即第n+1个区间的展示数目是第n-1个区间的展示数目与第n个区间中实际样本数目之和，通过设置 Histogram 函数中的 cumulative 属性实现，即cumulative=dict(enabled=True)。实际例子123456789101112131415161718192021222324252627import plotly as pyimport plotly.graph_objs as goimport numpy as npimport plotly.figure_factory as ffpyplt = py.offline.plot# Add histogram datas1 = np.random.RandomState(12)# 柯西分布x1 = s1.standard_cauchy(200) - 4 # 泊松分布x2 = s1.uniform(1,10,200) # Gamma 分布x3 = s1.standard_gamma(3,200) + 4 # 指数分布x4 = s1.exponential(3,200) + 8 # Group data togetherhist_data = [x1, x2, x3, x4]group_labels = [&apos;Group 1&apos;, &apos;Group 2&apos;, &apos;Group 3&apos;, &apos;Group 4&apos;]# Create distplot with custom bin_sizefig = ff.create_distplot(hist_data, group_labels, bin_size=.4)# Plot!pyplt(fig, filename=&apos;Distplot_with_Multiple_Datasets.html&apos;) 参数解读直方图案例中使用的 create_distplot 函数和 histogram 函数的常用参数。 histnorm：设置纵坐标显示格式，可选参数有””、percent、probability、density、probability density。若为percent或probability，则表示纵坐标显示样本占总体的百分比，所有矩形的高相加为100%；若为 density，则每个小矩形的面积为所在范围内的样本的数量，所有矩形面积相加为样本总数；若为probability density，则每个小矩形的面积为所在范围内的样本占总体的比例，所有面积数值相加为1。 histfunc：指定分组函数，可选参数有 count、sum、avg、min、max。若为count，则按照统计样本落在区间内的个数操作；若为sum、avg、min、max，则依次对样本区间内的样本求和、取平均值、求最小值和求最大值。 orientation：设置图形的方向，有v和h两个可选参数，v表示垂直显示，h表示水平显示。 cumulative：累积直方图参数，有 enabled、directio和currentbin 三个关键字。其中，enabled是布尔型，设置为 True 会显示累积直方图，设置为False则不对频率或频数进行累积；direction 用于设置累积方向，确定频率是从1～0（降序），还是从0到1（升序）；currentbin 有三个选择，即 include、exclude、half，为了防止偏差，一般选择half。 autobinx：布尔型，是否自动划分区间。 nbinsx：整型，最大显示区间数目。 xbins：设置划分区间属性，有 start、end、size 三个关键字。start 设置起始坐标，end 设置终止坐标，size 设置区间长度。]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>plotly</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[plotly基础图形-面积图]]></title>
    <url>%2F2019%2F02%2F25%2F1%2F</url>
    <content type="text"><![CDATA[plotly绘制面积图基本面积图：使用 Plotly 绘制面积图与绘制散点图和折线图相同，都使用 plotlygraph_objs 中的 Scatter 函数，不同之处在于面积图对于 fill 属性的设置，相当于在折线图的基础上对图形进行填充。。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import plotly as pyimport plotly.graph_objs as goimport numpy as np# Basic Overlaid Area Chartpyplt = py.offline.plot# 随机生成100个交易日的收益率s1 = np.random.RandomState(8) # 定义局部种子s2 = np.random.RandomState(9) # 定义局部种子rd1 = s1.rand(100)/10 - 0.02rd2 = s2.rand(100)/10 - 0.02# 设定初始资金initial1 = 100000initial2 = 100000total1 = []total2 = []for i in range(len(rd1)): initial1 = initial1*rd1[i] + initial1 initial2 = initial2*rd2[i] + initial2 total1.append(initial1) total2.append(initial2)trace1 = go.Scatter(# x = [1, 2, 3, 4],a y = total1, fill = &apos;tonexty&apos;, mode= &apos;none&apos;, # 无边界线 name = &quot;策略1&quot;)trace2 = go.Scatter(# x = [1, 2, 3, 4], y = total2, fill = &apos;tozeroy&apos;, mode= &apos;none&apos;,# 无边界线 name = &quot;策略2&quot;)data = [trace1, trace2]layout = dict(title = &apos;策略净值曲线&apos;, xaxis = dict(title = &apos;交易天数&apos;), yaxis = dict(title = &apos;净值&apos;), )fig = dict(data = data, layout = layout)pyplt(fig, filename=&apos;basic-area1.html&apos;) 内部填充面积图内部填充面积图仅填充两条曲线交叉所形成的面积部分，同样通过设置 fill 属性来完成，只需在原面积图的基础上设置第一条曲线无填充效果，即 fill = None，再设置第二条曲线的填充的效果为 tonexty，即 fill = ‘tonexty’。]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>plotly</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[plotly基础图形-甘特图]]></title>
    <url>%2F2019%2F02%2F25%2F1%2F</url>
    <content type="text"><![CDATA[plotly绘制甘特图甘特图（Gantt Chart）又称为横道图，通过条形来显示项目的进度、时间的安排等与时间相关的情况。绘制甘特图的函数是 Plotly.figure_factory 中的 create_gantt，通过传递包含事件（Task）与开始、结束（Start、Finish）时间的数据来绘制图表。甘特图的绘制也可以在markdown中完成。 甘特图(按数字索引)：将传入甘特图的数据按数字索引可以方便地对任务进行分类，本节中包含了6项工作，每项工作后的complete属性即为其对应的索引值，在create_gantt函数中设置 index_col=’Complete’，则有相同索引值的条形会呈现出相同的颜色，右侧的颜色条可以帮助用户根据颜色来判断任务大概对应的索引值是多少，这个数字的范围是0～100，用来反映工作完成的进度，100表示全部完成，0表示没有进展。 12345678910111213import plotly as pyimport plotly.figure_factory as ffpyplt = py.offline.plotdf = [dict(Task=&quot;Job A&quot;, Start=&apos;2009-01-01&apos;, Finish=&apos;2009-02-28&apos;, Complete=10，Resource=&apos;Sleep&apos;), dict(Task=&quot;Job B&quot;, Start=&apos;2008-12-05&apos;, Finish=&apos;2009-04-15&apos;, Complete=10), dict(Task=&quot;Job C&quot;, Start=&apos;2009-02-20&apos;, Finish=&apos;2009-05-30&apos;, Complete=50), dict(Task=&quot;Job D&quot;, Start=&apos;2009-03-20&apos;, Finish=&apos;2009-06-30&apos;, Complete=50), dict(Task=&quot;Job E&quot;, Start=&apos;2009-01-12&apos;, Finish=&apos;2009-04-28&apos;, Complete=100), dict(Task=&quot;Job F&quot;, Start=&apos;2009-03-07&apos;, Finish=&apos;2009-08-21&apos;, Complete=100)]fig = ff.create_gantt(df, index_col=&apos;Complete&apos;, show_colorbar=True)pyplt(fig, filename=&apos;gantt-numeric-variable.html&apos;) 甘特图（按类别索引）对甘特图的另一种索引方式是按照类别索引，本案例中包含8项工作，每项工作（数据）中的Resource代表此项工作所属的状态，状态分为Complete、Incomplete和Not Started三种，通过设置create_gantt函数中的index_col=’Resurce’ 即可完成通过Resource类别索引的目的。color属性用于设置不同状态对应的颜色，注意需要以字典的格式传递给create_gantt。使用 bar_width 设置任务条的宽度，使用 showgrid_x 与 showgrid_y 设置是否显示横、纵坐标轴，以及使用 title设置标题。 12345678910111213141516171819import plotly as pyimport plotly.figure_factory as ffpyplt = py.offline.plotdf = [dict(Task=&quot;Job-1&quot;, Start=&apos;2017-01-01&apos;, Finish=&apos;2017-02-02&apos;, Resource=&apos;Complete&apos;), dict(Task=&quot;Job-2&quot;, Start=&apos;2017-02-15&apos;, Finish=&apos;2017-03-15&apos;, Resource=&apos;Incomplete&apos;), dict(Task=&quot;Job-3&quot;, Start=&apos;2017-01-17&apos;, Finish=&apos;2017-02-17&apos;, Resource=&apos;Not Started&apos;), dict(Task=&quot;Job-4&quot;, Start=&apos;2017-01-17&apos;, Finish=&apos;2017-02-17&apos;, Resource=&apos;Complete&apos;), dict(Task=&quot;Job-5&quot;, Start=&apos;2017-03-10&apos;, Finish=&apos;2017-03-20&apos;, Resource=&apos;Not Started&apos;), dict(Task=&quot;Job-6&quot;, Start=&apos;2017-04-01&apos;, Finish=&apos;2017-04-20&apos;, Resource=&apos;Not Started&apos;), dict(Task=&quot;Job-7&quot;, Start=&apos;2017-05-18&apos;, Finish=&apos;2017-06-18&apos;, Resource=&apos;Not Started&apos;), dict(Task=&quot;Job-8&quot;, Start=&apos;2017-01-14&apos;, Finish=&apos;2017-03-14&apos;, Resource=&apos;Complete&apos;)]colors = &#123;&apos;Not Started&apos;: &apos;rgb(220, 0, 0)&apos;, &apos;Incomplete&apos;: (1, 0.9, 0.16), &apos;Complete&apos;: &apos;rgb(0, 255, 100)&apos;&#125;fig = ff.create_gantt(df, colors=colors, index_col=&apos;Resource&apos;, show_colorbar=True, title = &apos;Daily Schedule&apos;, bar_width = 0.8, showgrid_x = True, showgrid_y = True)pyplt(fig, filename=&apos;gantt-group-tasks-together.html&apos;)]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python，plotly</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[plotly基础图形-柱状图]]></title>
    <url>%2F2019%2F02%2F24%2F1%2F</url>
    <content type="text"><![CDATA[plotly绘制柱状图使用Plotly绘制基本柱状图最重要的函数是 graph_objs 中的 Bar 函数，通过传递数据，可以设置柱状图的样式。在 Layout 中对 barmode 进行设置可以绘制出不同类型的柱状图。 基础柱状图：在实际应用过程中，数据集往往并不完美，可能有缺失的数据，在Plotly中可以通过设置 Scatter 函数中的 connectgaps 属性来显示这些数据缺口或对缺口进行连接。 12345678910111213141516171819202122# -*- coding: utf-8 -*-import plotly as pyimport plotly.graph_objs as gopyplt = py.offline.plot# Tracetrace_basic = [go.Bar( x = [&apos;Variable_1&apos;, &apos;Variable_2&apos;, &apos;Variable_3&apos;,&apos;Variable_4&apos;,&apos;Variable_5&apos;], y = [1, 2, 3, 2, 4], )]# Layoutlayout_basic = go.Layout( title = &apos;The Graph Title&apos;, xaxis = go.XAxis(range = [-0.5,4.5], domain = [0,1]) )# Figurefigure_basic = go.Figure(data = trace_basic, layout = layout_basic)# Plotpyplt(figure_basic, filename=&apos;Basic_BarChart.html&apos;) 层叠柱状图层叠柱状图是对柱状图进行叠加，实现的方式是对 Layout 中的 barmode 属性进行设置，即设置 barmode=’stack。如果不进行 barmode 设置，我们就可以得到柱状簇，可以自己试一下。 123456789101112131415161718192021222324252627282930313233343536373839# -*- coding: utf-8 -*-# 2.6-3 应用案例import plotly as pyimport plotly.graph_objs as gopyplt = py.offline.plot# Stacked Bar Charttrace_1 = go.Bar( x = [&apos;华夏新经济混合&apos;, &apos;华夏上证50&apos;, &apos;嘉实新机遇混合&apos;, &apos;南方消费活力混合&apos;,&apos;华泰柏瑞&apos;], y = [0.7252, 0.9912, 0.5347, 0.4436, 0.9911], name = &apos;股票投资&apos;)trace_2 = go.Bar( x = [&apos;华夏新经济混合&apos;, &apos;华夏上证50&apos;, &apos;嘉实新机遇混合&apos;, &apos;南方消费活力混合&apos;,&apos;华泰柏瑞&apos;], y = [0.2072, 0, 0.4081, 0.4955, 0.02], name=&apos;其它投资&apos;)trace_3 = go.Bar( x = [&apos;华夏新经济混合&apos;, &apos;华夏上证50&apos;, &apos;嘉实新机遇混合&apos;, &apos;南方消费活力混合&apos;,&apos;华泰柏瑞&apos;], y = [0, 0, 0.037, 0, 0], name=&apos;债券投资&apos;)trace_4 = go.Bar( x = [&apos;华夏新经济混合&apos;, &apos;华夏上证50&apos;, &apos;嘉实新机遇混合&apos;, &apos;南方消费活力混合&apos;,&apos;华泰柏瑞&apos;], y = [0.0676, 0.0087, 0.0202, 0.0609, 0.0087], name=&apos;银行存款&apos;)trace = [trace_1, trace_2, trace_3, trace_4]layout = go.Layout( title = &apos;基金资产配置比例图&apos;, barmode=&apos;stack&apos;)fig = go.Figure(data = trace, layout = layout)pyplt(fig, filename=&apos;stacked_bar.html&apos;) 参数解读本小节对绘制柱状图所需 Bar 函数的常用参数进行详细讲解，包括设置柱状图所需的数据和属性，常用参数如下。 base：柱状图的起始参数。 dx、dy：x、y坐标轴的步进值，默认值是1。 error_x、error_y：x、y出错信息。 hoverinfo：当用户与图形互动时，鼠标指针显示的参数，包括x、y、z坐标数据，以及text（文字信息）和name（图形名称）数据等参数的组合，使用+、all、none和skip（忽略）作为组合连接符号，默认是● insidetextfont：内置文本的字体格式参数。 legendgroup：图标参数，默认是空字符串。 marker：数据节点参数，包括大小、颜色、格式等。 name：名称参数。 offset：坐标位移参数。 opacity：透明度参数，范围是0～1。 orientation：图形显示方向参数，包括v（垂直模式）和h（水平模式）。 outsidetextfont：外置文本的字体参数。 rsrc、xsrc、ysrc、textsrc、textpositionsrc、offsetsrc、basesrc、widthsrc：字符串源数组列表，作为Plotly网格标识符，用于设置一些特殊图表所需的r参数、x参数、y参数、text（文本）参数、textposition（文本位置）参数、offset（位移）参数、base（起点）参数、width（宽度）参数。 r、t：仅用于极坐标图，r用于设置径向坐标（半径），t用于设置角坐标。 showlegend：布尔变量，用于切换图标显示。 stream：数据流，用于实时同步数据图表。 textfont：文本字体参数，包括字体名称、颜色、大小等。 textposition：“文本”元素的位置参数，包括top left（左上）、topcenter（中上）、top right（右上）、middle left（左中）、middlecenter（中心）、middle right（右中）、bottom left（左下）、bottomcenter（中下）、bottom right（右下）模式。默认是middle center（中心）模式。 text：文本数据，设置与每个“（x,y）对”关联的文本元素，数组列表格式，默认是空字符串。 type：数据显示模式参数，包括constant（常数）、percent（百分比）、sqrt（平方根）和array（数组）。 visible：布尔变量，切换图形显示开关。 width：柱状图的条形宽度。 x0、y0：坐标轴起点坐标。 xaxis、yaxis：x、y 坐标参数。 xcalendar、ycalendar：坐标时间参数格式，默认是公历（gregorian）。 x、y： x、y轴的坐标数据。 其余柱状图补充 水平条形图：使用 Plotly 绘制水平条形图与绘制柱状图类似，只是需要在 Bar 函数中设置orientation = ‘h’，其余参数与柱状图相同。 瀑布式柱状图：瀑布式柱状图是层叠柱状图的一种衍生，通过选择性地显示层叠部分来实现柱状图的悬浮效果。]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>plotly</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[plotly基础图形-线形图]]></title>
    <url>%2F2019%2F02%2F22%2F1%2F</url>
    <content type="text"><![CDATA[plotly绘制线形图线形图的绘制在散点图的绘制中提及过，用 Plotly 绘制线形图使用 Scatter 函数。 线形图的数据缺口与连接：在实际应用过程中，数据集往往并不完美，可能有缺失的数据，在Plotly中可以通过设置 Scatter 函数中的 connectgaps 属性来显示这些数据缺口或对缺口进行连接。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283import plotly as pyimport plotly.graph_objs as gopyplt = py.offline.plotmonth = [&apos;January&apos;, &apos;February&apos;, &apos;March&apos;, &apos;April&apos;, &apos;May&apos;, &apos;June&apos;, &apos;July&apos;, &apos;August&apos;, &apos;September&apos;, &apos;October&apos;, &apos;November&apos;, &apos;December&apos;] # x轴坐标high_2000 = [32.5, 37.6, 49.9, 53.0, None, 75.4, 76.5, 76.6, 70.7, 60.6, 45.1, 29.3]low_2000 = [13.8, 22.3, 32.5, 37.2, None, 56.1, 57.7, 58.3, 51.2, 42.8, 31.6, 15.9]high_2007 = [36.5, 26.6, 43.6, 52.3, None, 81.4, 80.5, 82.2, 76.0, 67.3, 46.1, 35.0]low_2007 = [23.6, 14.0, 27.0, 36.8, None, 57.7, 58.9, 61.2, 53.3, 48.5, 31.0, 23.6]high_2014 = [28.8, 28.5, 37.0, 56.8, None, 79.7, 78.5, 77.8, 74.1, 62.6, 45.3, 39.9]low_2014 = [12.7, 14.3, 18.6, 35.5, None, 58.0, 60.0, 58.6, 51.7, 45.2, 32.2, 29.1]# 6组数据# Create and style tracestrace0 = go.Scatter( x = month, y = high_2014, name = &apos;High 2014&apos;, line = dict( color = (&apos;rgb(205, 12, 24)&apos;), width = 4), connectgaps = True)trace1 = go.Scatter( x = month, y = low_2014, name = &apos;Low 2014&apos;, line = dict( color = (&apos;rgb(22, 96, 167)&apos;), width = 4,), connectgaps = False)trace2 = go.Scatter( x = month, y = high_2007, name = &apos;High 2007&apos;, line = dict( color = (&apos;rgb(205, 12, 24)&apos;), width = 4, dash = &apos;dash&apos;), connectgaps = False)# dash虚线（短线），dot虚线（点），dashdot （）trace3 = go.Scatter( x = month, y = low_2007, name = &apos;Low 2007&apos;, line = dict( color = (&apos;rgb(22, 96, 167)&apos;), width = 4, dash = &apos;dash&apos;), connectgaps = False)trace4 = go.Scatter( x = month, y = high_2000, name = &apos;High 2000&apos;, line = dict( color = (&apos;rgb(205, 12, 24)&apos;), width = 4, dash = &apos;dot&apos;), connectgaps = False)trace5 = go.Scatter( x = month, y = low_2000, name = &apos;Low 2000&apos;, line = dict( color = (&apos;rgb(22, 96, 167)&apos;), width = 4, dash = &apos;dot&apos;), connectgaps = False)data = [trace0, trace1, trace2, trace3, trace4, trace5]# Edit the layoutlayout = dict(title = &apos;Average High and Low Temperatures in New York&apos;, xaxis = dict(title = &apos;Month&apos;), yaxis = dict(title = &apos;Temperature (degrees F)&apos;), )fig = dict(data=data, layout=layout)pyplt(fig, filename=&apos;styled-line.html&apos;) 在数据部分，原先的缺失数据被设置为 None。在 Scatter 函数中，设置 connectgaps 属性为 Fasle，表示不连接，显示数据缺口；设置 connectgaps 属性为 True，表示连接缺失值左右相邻的数据点。在图中，对 “High 2014” 线形图进行了连接，其他线条则采用显示缺口的形式。Scatter 函数中的 line 属性用于对线形图的样式进行控制； color 用于设置颜色；width 用于设置宽度；dash 用于设置类型，dash 表示由短线组成的虚线，dot 表示由点组成的虚线，dashdot 表示由点和短线组成的虚线。 数据插入值通过调整 Scatter 函数 line 属性中的 shape 值可以对插值的方法进行控制，完成数据点的插值设置。插值的方法简单来说就是根据已有的零散数据点，找到一条满足一定条件的曲线，使之经过全部的数据点。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import plotly as pyimport plotly.graph_objs as gopyplt = py.offline.plottrace1 = go.Scatter( x=[1, 2, 3, 4, 5], y=[1, 3, 2, 3, 1], mode=&apos;lines+markers&apos;, name=&quot;&apos;linear&apos;&quot;, hoverinfo=&apos;name&apos;, line=dict( shape=&apos;linear&apos; ))trace2 = go.Scatter( x=[1, 2, 3, 4, 5], y=[6, 8, 7, 8, 6], mode=&apos;lines+markers&apos;, name=&quot;&apos;spline&apos;&quot;, text=[&quot;tweak line smoothness&lt;br&gt;with &apos;smoothing&apos; in line object&quot;], hoverinfo=&apos;text+name&apos;, line=dict( shape=&apos;spline&apos; ))trace3 = go.Scatter( x=[1, 2, 3, 4, 5], y=[11, 13, 12, 13, 11], mode=&apos;lines+markers&apos;, name=&quot;&apos;vhv&apos;&quot;, hoverinfo=&apos;name&apos;, line=dict( shape=&apos;vhv&apos; ))trace4 = go.Scatter( x=[1, 2, 3, 4, 5], y=[16, 18, 17, 18, 16], mode=&apos;lines+markers&apos;, name=&quot;&apos;hvh&apos;&quot;, hoverinfo=&apos;name&apos;, line=dict( shape=&apos;hvh&apos; ))trace5 = go.Scatter( x=[1, 2, 3, 4, 5], y=[21, 23, 22, 23, 21], mode=&apos;lines+markers&apos;, name=&quot;&apos;vh&apos;&quot;, hoverinfo=&apos;name&apos;, line=dict( shape=&apos;vh&apos; ))trace6 = go.Scatter( x=[1, 2, 3, 4, 5], y=[26, 28, 27, 28, 26], mode=&apos;lines+markers&apos;, name=&quot;&apos;hv&apos;&quot;, hoverinfo=&apos;name&apos;, line=dict( shape=&apos;hv&apos; ))data = [trace1, trace2, trace3, trace4, trace5, trace6]layout = dict( legend=dict( y=0.5, traceorder=&apos;reversed&apos;, font=dict( size=16 ) ))fig = dict(data=data, layout=layout)pyplt(fig, filename=&apos;line-shapes.html&apos;) 如上图所示 Plotly 提供的插值方法有 6种，分别是 ‘linear’、’spline’、’hv’、’vh’、’hvh’和’vhv’。例如，设置 shape=’spline’。 填充线形图填充线形图是线形图的一种衍生，通过选择性地显示线条和对线条图进行填充来完成。这部分平常用的比较少，所以就不再说明。有兴趣的可以搜一下《基于Plotly的动态可视化绘图》，本文就是此书的一个学习笔记，这本书除了有基础的Plotly绘图学习，而且还有大量的实例。]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>plotly</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[plotly基础图形-气泡图]]></title>
    <url>%2F2019%2F02%2F22%2F1%2F</url>
    <content type="text"><![CDATA[plotly绘制气泡图气泡图的实现方法与散点图的实现方法类似，修改散点图中的点的大小，就变成了气泡图。 实现代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import plotly as pyimport plotly.graph_objs as go# ----------pre defpyplt = py.offline.plot# ----------codetrace0 = go.Scatter( x=[1, 2, 3, 4], y=[10, 11, 12, 13], text=[&apos;A&lt;/br&gt;size: 40&lt;/br&gt;default&apos;, &apos;B&lt;/br&gt;size: 60&lt;/br&gt;default&apos;, &apos;C&lt;/br&gt;size: 80&lt;/br&gt;default&apos;, &apos;D&lt;/br&gt;size: 100&lt;/br&gt;default&apos;], mode=&apos;markers&apos;, name=&apos;default&apos;, marker=dict( size=[400, 600, 800, 1000], sizemode=&apos;area&apos;, color= [120, 125, 130, 135], opacity=[1, 0.8, 0.6, 0.4], showscale= False, ))trace1 = go.Scatter( x=[1, 2, 3, 4], y=[14, 15, 16, 17], text=[&apos;A&lt;/br&gt;size: 40&lt;/br&gt;sizeref: 0.2&apos;, &apos;B&lt;/br&gt;size: 60&lt;/br&gt;sizeref: 0.2&apos;, &apos;C&lt;/br&gt;size: 80&lt;/br&gt;sizeref: 0.2&apos;, &apos;D&lt;/br&gt;size: 100&lt;/br&gt;sizeref: 0.2&apos;], mode=&apos;markers&apos;, name = &apos;ref0.2&apos;, marker=dict( size=[400, 600, 800, 1000], sizeref=0.2, sizemode=&apos;area&apos;, ))trace2 = go.Scatter( x=[1, 2, 3, 4], y=[20, 21, 22, 23], text=[&apos;A&lt;/br&gt;size: 40&lt;/br&gt;sizeref: 2&apos;, &apos;B&lt;/br&gt;size: 60&lt;/br&gt;sizeref: 2&apos;, &apos;C&lt;/br&gt;size: 80&lt;/br&gt;sizeref: 2&apos;, &apos;D&lt;/br&gt;size: 100&lt;/br&gt;sizeref: 2&apos;], mode=&apos;markers&apos;, name=&apos;ref2&apos;, marker=dict( size=[400, 600, 800, 1000], sizeref=2, sizemode=&apos;area&apos;, ))data = [trace0, trace1, trace2]pyplt(data, filename=&apos;bubble_scale.html&apos;) 参数解读气泡图与散点图使用的是同一个函数，因此大部分参数在上篇文章中已经介绍过了，这里对本节所涉及的参数进行补充说明。 text：列表，元素为相应节点的悬浮文字内容。 marker：数据节点参数，包括大小、颜色、格式等，有如下设置项。 size：列表，元素为相应节点的尺寸大小。 sizeref：缩放的比例，如设置为2，则缩小为原来的1/2。 sizemode：缩放的标准，默认以 diameter（直径）缩放，也可选择以 area（面积）缩放。 showscale：默认为False，不显示右侧的颜色条，也可以选择True。 pacity：列表，元素为0～1之间的数，表示相应节点的透明度。]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>plotly</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[plotly基础图形-散点图]]></title>
    <url>%2F2019%2F02%2F22%2F1%2F</url>
    <content type="text"><![CDATA[plotly绘制散点图线形图又称为曲线图，是最常用的图形类型。与传统的绘图软件不同，Plotly没有独立的线形图函数，而是把线形图与散点图全部用 Scatter 函数实现。 代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import plotly as pyimport plotly.graph_objs as go# ----------pre defpyplt = py.offline.plot# ----------code# Create random data with numpyimport numpy as npN = 100random_x = np.linspace(0, 1, N)random_y0 = np.random.randn(N) + 5random_y1 = np.random.randn(N)random_y2 = np.random.randn(N) - 5# Create tracestrace0 = go.Scatter( x = random_x, y = random_y0, mode = &apos;markers&apos;, # 纯散点的绘图 name = &apos;markers&apos;, # 曲线名称 marker = dict( size = 10, # 设置点的宽度 color = &apos;rgba(152, 0, 0, .8)&apos;, # 设置曲线的颜色 line = dict( width = 2, # 设置线条的宽度 color = &apos;rgb(0, 0, 0)&apos; # 设置线条的颜色 ) ))trace1 = go.Scatter( x = random_x, y = random_y1, mode = &apos;lines+markers&apos;, # 散点+线的绘图 name = &apos;lines+markers&apos;, marker = dict( size = 10, color = &apos;rgba(255, 182, 193, .9)&apos;, line = dict( width = 2, ) ))trace2 = go.Scatter( x = random_x, y = random_y2, mode = &apos;lines&apos;, # 线的绘图 name = &apos;lines&apos;)data = [trace0, trace1, trace2]layout = dict(title = &apos;Styled Scatter&apos;, yaxis = dict(zeroline = True), # 显示y轴的0刻度线 xaxis = dict(zeroline = False) # 不显示x轴的0刻度线 )fig = dict(data=data, layout=layout)pyplt(fig, filename=&apos;scatter_basic_demo.html&apos;) 参数解读下边的参数在后续的线性图中有更多的介绍。 markers、lines和lines+markers三个图形的输出格式不同，是因为Scatter函数中的mode参数不同,代码中已经做了注释。 connectgaps：布尔变量，用于连接缺失数据。 dx、dy：x、y坐标轴的步进值，默认值是1。 error_x、error_y：x、y出错信息。 fillcolor：填充颜色。 fill：填充模式，包括格式、颜色等。 hoverinfo：当用户与图形互动时，鼠标指针显示的参数，包括x、y、z坐标数据，以及 text（文字信息）、name（图形名称）等参数的组合，可使用+、all、none和skip（忽略）作为组合连接符号，默认是all（全部消失）。 hoveron：当用户与图形互动时，鼠标指针显示的模式，包括points（点图）、fills（填充图）和points+fills（点图+填充图）三种模式。 ids：在动画图表中，数据点和图形key键的列表参数。 legendgroup：图例参数，默认是空字符串。 line：线条参数，包括线条宽度、颜色、格式。 marker：数据节点参数，包括大小、颜色、格式等。 mode：图形格式，包括lines（线形图）、markers（散点图）和text（文本），使用+或none等符号进行模式组合。 name：名称参数。 opacity：透明度参数，范围是0～1。 rsrc、xsrc、ysrc、tsrc、idssrc、textsrc、textpositionsrc：字符串源数组列表，可作为Plotly网格标识符，用于设置特殊图表所需的r参数、x参数、y参数、t参数、ids参数、text（文本）参数和textposition（文本位置）参数。 r、t：仅用于极坐标图，r用于设置径向坐标（半径），t用于设置角坐标。 showlegend：布尔变量，用于切换图标显示。 stream：数据流，用于实时显示数据图表。 textfont：文本字体参数，包括字体名称、颜色、大小等。 textposition：“文本”元素的位置参数，包括top left（左上）、topcenter（中上）、top right（右上）、middle left（左中）、middlecenter（中心）、middle right（右中）、bottom left（左下）、bottomcenter（中下）、bottom right（右下）模式，默认是middle center（中心）模式。 text：文本数据，设置与每个“（x，y）对”关联的文本元素和数组列表格式，默认是空字符串。 type：数据显示模式，包括constant（常数）、percent（百分比）、sqrt（平方根）、array（数组）模式。 x0、y0：坐标轴起点坐标。 xaxis，yaxis：x、y 坐标参数。 xcalendar、ycalendar：坐标时间参数的格式，默认是公历（gregorian），支持gregorian、chinese、coptic、discworld、ethiopian、hebrew、islamic、julian、mayan、nanakshahi、nepali、persian、jalali、taiwan、thai和 ummalqura 格式。 x，y：设置x、y轴的坐标数据。]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>plotly</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[plotly基础案列和绘图流程]]></title>
    <url>%2F2019%2F02%2F21%2F1%2F</url>
    <content type="text"><![CDATA[Plotly 基础案列解读12345678910111213141516import plotly as pyfrom plotly.graph_objs import Scatter, Layout, Datapy.offline.init_notebook_mode()trace0 = Scatter( x=[2, 5, 7, 10], y=[12, 14, 16, 19])trace1 = Scatter( x=[3, 4, 5, 9], y=[11, 12, 14, 17])data = Data([trace0, trace1])py.offline.iplot(data, filename = &apos;first_offline_start&apos;) 第1 ~ 4行，import 所需的模块库。 第 4 行开启notebook绘图模式。 第6行，定义一个名为trace0的变量，用于保存绘图数据；Plotly 一般称一个绘图对象为 trace（画痕、画轨、画迹）；每个绘图对象都由Plotly模块库里面的 graph_objs （图像对象）子模块的 Scatter （数据布局）对象定义；Scatter 对象的输入数据与 Plotly绘图模块库中的许多函数和对象一样，都是字典格式，而且接受多种复杂的复合字典格式。 第7～8行，定义变量 trace0 的 x 和 y 坐标，坐标采用列表数据格式，坐标 x、y 的数据长度必须一样，不然会出现空缺坐标；其中的 x、y 字符是 Plotly 模块库 Scatter 对象的内部变量名称，类似关键字。 第10～12行，定义另外一条曲线 trace1 的坐标数据，细节参见第6～8行的说明。 第14行，定义一个变量名 data，通过 plotly.graph_objs 模块库的Data函数，把代表两条曲线的变量trace0和trace1定义为一组图形数据，注意Data函数的输入参数是列表数据格式，所以要在变量trace0和trace1外面加上表示列表的“[]”符号。 第16行，根据data变量的数据绘制图形。基础绘图流程经过以上分析，使用Plotly绘图模块库进行绘图的完整流程应该包括以下命令。 添加图轨数据（add_trace），使用的是Scatter等函数命令。 设置画面布局，使用layout命令。 集成图形、布局数据，命令有Data、Figure。 绘制图形的输出，命令是offline.plot。可以自定义命令。]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>plotly</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[plotly学习笔记（一）]]></title>
    <url>%2F2019%2F02%2F19%2F1%2F</url>
    <content type="text"><![CDATA[Plotly 简介Pandas 和 Plotly 交互式绘图模块可以称为Python数据分析和Python量化分析两大重量级模块库。Plotly绘图底层使用的是plotly.js，plotly.js基于D3.js、stack.gl（WebGL组件库，由Plotly团队的Mikola Lysenko带领开发）和SVG，用JavaScript在网页上实现类似MATLAB和Python Matplotlib的图形展示功能，支持数十种图形，包括2D和3D图形，交互流畅，可以满足一般科学计算的需要。该项目成功后，开始向其他语言移植，目前已经有Python、MATLAB、R语言、Jupyter等多种版本的API接口。Plotly绘图模块库可直接生成PNG等图像文件，与Bokeh绘图模块库和各种基于Web的JavaScript图表模块库类似，生成的是一个内置JavaScript脚本的HTML网页文件，虽然文件比Bokeh绘图模块库生成的文件略大，但在互动性方面，Plotly绘图模块库强大得多。 Plotly 离线绘图本文以及后续都会使用离线绘图，如果对在线绘图有兴趣的话可以看下官方文档，离线绘图均在 jupyter notebook 中进行。 Plotly的离线绘图功能有两种方法：plotly.offline.plot ()和plotly.offline.iplot ()。 使用plotly.offline.plot ()方法会在本地新建一个HTML文件，并可以选择是否在浏览器中打开这个文件。 使用plotly.offline.iplot ()方法会在Jupyter Notebook 中直接绘图，而不需要新建一个HTML文件。现在举一个简单的例子，后续进行详细的介绍:12345678910111213141516import plotly as pyfrom plotly.graph_objs import Scatter, Layout, Datapy.offline.init_notebook_mode()trace0 = Scatter( x=[2, 5, 7, 10], y=[12, 14, 16, 19])trace1 = Scatter( x=[3, 4, 5, 9], y=[11, 12, 14, 17])data = Data([trace0, trace1])py.offline.iplot(data, filename = &apos;first_offline_start&apos;) 输出图片如下，值得说明的是，输出图形本身是有很强的交互式，可以参考plotly介绍]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>plotly</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python可视化神器-plotly]]></title>
    <url>%2F2019%2F02%2F18%2F1%2F</url>
    <content type="text"><![CDATA[本文是浏览 medium 时发现的，这篇文章可以让我们认识到 plotly 的存在使数据可视化分析操作更加简易，交互性更强，效率更高。原文链接The Next Level of Data Visualization in Python数据来源: medium数据注:原文需翻墙，所以进行了转载翻译 plotly简介plotly是一款基于D3.js框架的Python库，Plotly中绘制图像有在线和离线两种方式，因为在线绘图需要注册账号获取API key，较为麻烦，所以本文仅介绍离线绘图的方式。离线绘图又有plotly.offline.plot()和plotly.offline.iplot()两种方法，前者是以离线的方式在当前工作目录下生成html格式的图像文件，并自动打开；后者是在jupyter notebook中专用的方法，即将生成的图形嵌入到ipynb文件中。文中的所有工作都是使用 plotly + cufflinks 在Jupyter笔记本中离线运行完成。 用 pip 安装 plotly 和 cufflinks，在 jupyter 导入 cufflinks plotly 运行： 12345678# 导入 plotlyimport plotly.plotly as pyimport plotly.graph_objs as gofrom plotly.offline import iplot, init_notebook_mode# 在离线模式下使用 cufflinks plotlyimport cufflinkscufflinks.go_offline(connected=True)init_notebook_mode(connected=True) 单变量分布：柱状图和箱线图12df[&apos;claps&apos;].iplot(kind=&apos;hist&apos;, xTitle=&apos;claps&apos;, yTitle=&apos;count&apos;, title=&apos;Claps Distribution&apos;) 相比较那些习惯 matplotlib，我们所要做的就是再添加一个字母 i (iplot），就可以得到一个交互式更强的图表，我们可以点击数据来获取更多细节，放大图的各个部分，选择显示不同的类别。 如果我们需要柱状图重叠效果，那也是非常的简单： 1234567df[[&apos;time_started&apos;, &apos;time_published&apos;]].iplot( kind=&apos;hist&apos;, histnorm=&apos;percent&apos;, barmode=&apos;overlay&apos;, xTitle=&apos;Time of Day&apos;, yTitle=&apos;(%) of Articles&apos;, title=&apos;Time Started and Time Published&apos;) 只需要简单操作一下 pandas ，我们就可以绘制条形图： 123456＃重新采样到每月频率并绘制df2 = df[[&apos;view&apos;,&apos;reads&apos;,&apos;published_date&apos;]].\ set_index(&apos;published_date&apos;).\ resample(&apos;M&apos;).mean()df2.iplot(kind=&apos;bar&apos;, xTitle=&apos;Date&apos;, yTitle=&apos;Average&apos;, title=&apos;Monthly Average Views and Reads&apos;)） 我们可以用 pandas + plotly + cufflink。对于不同的粉丝数量来进行箱线图的绘制: 1234df.pivot(columns=&apos;publication&apos;, values=&apos;fans&apos;).iplot( kind=&apos;box&apos;, yTitle=&apos;fans&apos;, title=&apos;Fans Distribution by Publication&apos;) 箱线图中有很多信息，如果看不到数字我们会错失很多东西，交互性的好处就在于此，我们根据自己的需求来展示对应的数据。 散点图它将所有的数据以点的形式展现在直角坐标系上，以显示变量之间的相互影响程度，点的位置由变量的数值决定。通过观察散点图上数据点的分布情况，我们可以推断出变量间的相关性。如果变量之间不存在相互关系，那么在散点图上就会表现为随机分布的离散的点，如果存在某种相关性，那么大部分的数据点就会相对密集并以某种趋势呈现。数据的相关关系主要分为：正相关（两个变量值同时增长）、负相关（一个变量值增加另一个变量值下降）、不相关、线性相关、指数相关等。 时间序列时间序列（或称动态数列）是指将同一统计指标的数值按其发生的时间先后顺序排列而成的数列。时间序列分析的主要目的是根据已有的历史数据对未来进行预测。下边让我们制作一片关于我的 TDS 文章的数据框，看看趋势是如何变化的。 1234567tds = df[df[&apos;publication&apos;] == &apos;Towards Data Science&apos;].\ set_index(&apos;published_date&apos;)# 绘制时间序列图tds[[&apos;claps&apos;, &apos;fans&apos;, &apos;title&apos;]].iplot( y=&apos;claps&apos;, mode=&apos;lines+markers&apos;, secondary_y = &apos;fans&apos;, secondary_y_title=&apos;Fans&apos;, xTitle=&apos;Date&apos;, yTitle=&apos;Claps&apos;, text=&apos;title&apos;, title=&apos;Fans and Claps over Time&apos;) 在这一行中我们做了很多事情： 自动生成合适的时间序列x轴 因为变量的范围有所不同，所以我们添加了辅助 Y 轴 添加文章标题作为悬停信息我们还可以添加更加详细的文本注释：12345678tds_monthly_totals.iplot( mode=&apos;lines+markers+text&apos;, text=text, y=&apos;word_count&apos;, opacity=0.8, xTitle=&apos;Date&apos;, yTitle=&apos;Word Count&apos;, title=&apos;Total Word Count by Month&apos;) 对于由第三个分类变量着色的双变量散点图，我们使用： 12345678df.iplot( x=&apos;read_time&apos;, y=&apos;read_ratio&apos;, # Specify the category categories=&apos;publication&apos;, xTitle=&apos;Read Time&apos;, yTitle=&apos;Reading Percent&apos;, title=&apos;Reading Percent vs Read Ratio by Publication&apos;) 数据可视化进阶现在，我们将讨论一些您可能不会经常使用的情节，但这些情节可能会令人印象深刻。 散射矩阵当我们想探索多个变量之间的关系时，散射矩阵（也称为SPLOM）是一个很好的选择： 123456import plotly.figure_factory as fffigure = ff.create_scatterplotmatrix( df[[&apos;claps&apos;, &apos;publication&apos;, &apos;views&apos;, &apos;read_ratio&apos;,&apos;word_count&apos;]], diag=&apos;histogram&apos;, index=&apos;publication&apos;) 这些图都是完全的交互式，可以让我们查看任何想知道的数据。 热力图为了可视化数值变量之间的相关性，我们计算相关性，然后制作一个带注释的热力图： 1234567corrs = df.corr()figure = ff.create_annotated_heatmap( z=corrs.values, x=list(corrs.columns), y=list(corrs.index), annotation_text=corrs.round(2).values, showscale=True) Cufflinks 也有几个主题，我们可以选自己中意的风格。例如： 我们也可以得到3D图形： 结论我们在看完这些演示后就明白了我们在以往的绘图过程中浪费了多少时间精力。到目前为止，在Python中执行所有这些操作的最佳选择是plotly。Plotly允许我们快速地进行可视化，并通过交互帮助我们更好地洞察数据。]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MVP-最小化可行产品]]></title>
    <url>%2F2018%2F11%2F17%2F1%2F</url>
    <content type="text"><![CDATA[MVP(Minimum Viable Product)——“最小化可行产品”。很多产品书中都会提到的一个概念。我对此有模糊概念的时候，是在阅读《腾讯传》里面提出的一句话“腾讯——‘小步快跑，快速迭代’造就的企业”。“小步快跑，快速迭代”翻译一下就是’上线-反馈-修改-上线”这样反复更新内容的过程，来达到一个和市场契合的状态。 MVP 是将产品用最简洁的实现方式，开发出来，过滤冗余杂和高级特性，快速投入市场让用户使用，并且不断地收取反馈信息，进行下一次迭代，尽早达到 PMF 状态。 为什么使用MVP？你需要用一个最小可行性的模型去验证需求。用最小的代价去验证用户是否买账，就算是验证出来是伪需求，也方便及时调整方向或止损。 MVP设计核心 最小可行化产品: 在初期设计开发中应该明白目的是什么，明白自己的核心需求我们应该用 MVP 去验证两个问题：产品是否满足用户需求；用户是否为产品买单？ 用户反馈： 在快速迭代的过程中我们应该随时收集核心用户的反馈意见，从中挖掘出来有价值的需求。用户的反馈结果是开发产品决策的根本依据。 快速迭代：‘小步快跑，快速迭代’就是针对用户反馈结果的快速验证，是否符合用户真实的想法。’上线-反馈-修改-上线”就这样，一直达到和用户市场契合的状态。怎么做MVP 用户访谈面对面直接对产品的受众用户进行调研。但是在调研过程中，一定要注意样本选择的质和量。有时候用户也会因为各种方面的原因，表达的想法可能不是用户真正的想法。 演示DemoDropbpx创始人就曾经只是对产品只进行了视频宣传，由宣传后得到的用户结果来确定是否开发。 众筹可以在目标用户中进行众筹，一方面参与感在于吸引更多的人来关注，另一个方面就是在于对产品的估值对产品面试前的一个估计。 手动式MVP手动式MVP典型例子就是Zappos，Zappos创始人跑到隔壁鞋店拍摄了鞋子照片，放到了网上，当有人下单时。去隔壁店买鞋然后递出去。通过这种方法来验证人们网购的需求。 上述方法验证了想法后，可以快速的设计出一个Html页面，App程序，微信小程序等投入市场，等待用户反馈，进行快速迭代。 用户反馈设计细节 反馈渠道简单方便：产品内部，微博，微信，qq 人人参与：通过设置合理的酬赏使更多人参与 数据埋点：A/B测试等方法， 通过数据来验证]]></content>
      <categories>
        <category>产品之路</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[“抄袭”中杀出的中国互联网]]></title>
    <url>%2F2018%2F11%2F02%2F1%2F</url>
    <content type="text"><![CDATA[一代互联网，半部抄袭史在中国第一波互联网发展热潮中，什么都可以模仿。在那个年代，模仿存在于各个行业。甚至连公司的命名方式都在模仿。中国的第一个搜索引擎建立者张朝阳把自己的公司命名为 “Sohoo”，仿照了 “Yahoo”。《福布斯》曾经在一篇报道中把美团点评创始人王兴称为“克隆家”。因为王兴的三家创业公司校内、饭否和美团，创立时分别模仿当时硅谷最红的创业公司脸书、推特和Groupon。我们可以简单的梳理一下互联网产品：QQ抄袭ICQ、微信抄袭KIKI、淘宝抄袭ebay，支付宝抄袭paypal、百度抄袭谷歌、微博抄袭tiwtter、优酷抄袭Youtube、美团抄袭Groupon、滴滴抄袭uber。在很多人(包括我很早的时候)的认知里，中国互联网的成功来源与中国政策对外来企业的限制。在后来学习的过程中，我为自己当年的无知感到羞愧。中国的众多互联网企业家创造了值得我们尊重的企业。前不久，百度因为某些事件上了微博热搜，许多人认为，如果不是谷歌因为被迫退出中国市场，哪有百度？李彦宏发朋友圈：这些年来，百度一直被认为是占了Google退出中国的便宜。百度无法证明一件没有发生的事情。如果现在Google回来，我们正好可以真刀真枪的再PK一次，再赢一次。。 中国人更懂中国人我们简单的来看一下互联网产品发展历史，就可以明白这种说法的局限性。 OICQ 与 ICQ腾讯被著称以抄袭起家。QQ 的前身 OICQ 抄的就是 ICQ。在 OICQ 开发的过程，ICQ 已经成熟，并且进入了中国市场，在市面上，还有几种 汉化版的 OICQ。腾讯在这场战役中取得胜利。OICQ 的胜利来自于一系列细微的创意和设计,来自于腾讯更懂中国市场。比如中国个人电脑普及率很低，大多数都在网吧使用 OICQ 换一台电脑，用户信息就会丢失，腾讯把用户信息好友名单放到了后台，这样就不会丢失。等等一系列技术的微创新彻底击败了其他通讯软件。 QQ 与 MSN2000年4月,腾讯为了避免与ICQ间的纠纷，腾讯公司决定全面更换OICQ的名称，改称我们熟悉的“腾讯QQ”。那年我 5 岁，不知道 腾讯 不知道 QQ。2005年。MSN在没有任何支持与宣传的情况下市场份额为 10.85%。QQ 为77.8%。同时微软宣布本土化作战。10月13日，微软与雅虎宣布合作使其全球的即时通信用户之间都能实现互联互通。并且向腾讯发出邀请，马化腾坚决的拒绝。最终的结局又是 QQ 的胜利。 淘宝 与 eBAY2003年3月，eBay收购中国最大的在线交易社区易趣网。与此同时，马云创办淘宝网。两者爆发对抗性的抗争。淘宝网的核心武器”基本功能免费+增值功能收费”，当时的eBay上发布商品需要收费，商品售出收费，PayPal 付款收费。eBay的“免费不是商业模式”决定了它在中国的命运。 百度 与 谷歌“天下苦百度久矣”。百度的竞价排名让如今的中国人抱怨连天。百度核心功能和极简主义的设计风格借鉴了谷歌。但是其中有很多细小的差异化。在我体验百度和谷歌功能的时候，有一点印象特别深刻：谷歌是用户点击一个搜索结果，就会离开搜索界面。百度则是点击搜索结果开启一个新的界面，依旧可以返回原有的结果。在营收上谷歌采取的是关键词广告，根据用户的浏览或者搜索将特定广告放到用户面前。百度则是我们熟悉的竞价排名。谷歌搜索在2005年进入中国到2010年被迫离开，都未能赶超百度。 这样的例子多不胜数，Hotmail与网易邮箱，亚马逊与当当，滴滴和Uber，美团与Groupon。我们在总结分析的时候，不要只是认为是中国政策对本土企业的保护的原因，更是要看到中国企业在斗争时不断地微创新，这种创新是无可比拟的。 折戟沉沙的硅谷在国外巨头本土化作战中国的时候，谷歌启用李开复对标百度。微软罗川用 msn 作战 QQ。MSN,谷歌相继失败后，作为两个产品的中国区负责人李开复和罗川有着相应的心情。MSN 和谷歌的每一项功能的开发都需要到美国总部进行论证，当投入研发时，用户早已流失。硅谷不投入资源，团队没有自由，产品的核心功能产品不为中国用户妥协。在以上帝的角度看来，国外巨头在中国本土化作战如果启用一个新的产品，用硅谷高端的技术，充沛的资金去铺路，结果可能或许不一样。事实证明，硅谷的全球一体化产品在中国并不适用。在黑头发，黑眼睛，黄皮肤的眼里，外来的和尚不一定好念经，显然本土企业更懂他们。最后，借用刚开始李彦宏的一句话:”如果硅谷企业重回中国，真刀真枪的再PK一次，我们还会再赢一次。” 阅读《腾讯传》，《AI 未来》有感]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[推荐系统中的数据挖掘方法]]></title>
    <url>%2F2018%2F07%2F14%2F1%2F</url>
    <content type="text"><![CDATA[1. 推荐系统中的数据挖掘方法概览&emsp;&emsp;数据挖掘过程一般是由三个连续的执行步骤组成，本章不会过多的介绍这些方法，只是做一个总结，详细的过程以及公式推导建议大家去阅读《统计学方法》以及《推荐系统 技术、评估及高效算法》。。]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[基于内容的语义感知系统]]></title>
    <url>%2F2018%2F07%2F04%2F1%2F</url>
    <content type="text"><![CDATA[1. 基于内容的推荐系统&emsp;&emsp;基于内容的推荐系统依赖物品和用户描述内容来构建其特征表示，然后基于这些特征表示推荐与目标用户曾明确表达过喜好的物品相类似的物品。该类推荐系统的基本过程是对目标用户属性(偏好，兴趣)与物品属性进行匹配，并返回目标用户在物品上的喜好程度。&emsp;&emsp;CRRS（基于内容的推荐系统）的高层次架构图如下，推荐的过程有三个阶段。每一个阶段由独立的部件控制。 内容分析器：当信息没有结构化时（如文本），某些预处理阶段需要抽取相关的结构化信息。这个部件的主要功能就是将来自信息源的对象（如文档、网页、新闻、产品描述等）的内容表示成恰当的格式，以便于下一阶段的处理。数据对象经过特征抽取技术的分析，目的是将原始信息空间转换到想要的物品描述格式（如将网页表示成关键词向量）。这样的描述格式作为信息学习器和过滤组件的输入。 信息学习器：这个模块收集了有关用户偏好的数据特征，并试图去泛化这些数据，从而构建用户特征信息。泛化策略通常是通过机器学习技术实现的，它可以从用户过去喜欢的或不喜欢的物品中推断出一个用户的兴趣模型。例如，网页推荐的信息学习器可以实现相关的反馈方法，通过学习技术将正负样例向量组合到一个表示用户特征的模型向量中。训练样本是由用户提供的具有正负反馈的网页。 过滤组件：这个模块将用户个人信息和物品在表示空间进行匹配，利用用户个人信息来推荐相关物品。这个组件的结果是一个二元的或者连续型的相关性判断（使用某种相似度来计算），后者能生成一个潜在感兴趣物品的排名清单。在上面提过的例子中，这种匹配是通过计算原型向量和物品向量的余弦相似度得到的。 &emsp;&emsp;推荐步骤的第一个阶段是由内容分析器完成的，它通常是借鉴了信息检索系统的技术。来自信息源的物品描述经过内容分析器，从非结构化的文本中抽取特征（如关键词、n-grams、概念等），从而得到结构化的物品描述，并储存在被表示物品库中。&emsp;&emsp;为了结构化和更新活跃用户Ua(必须为其提供推荐的用户)的个人信息，该用户对物品的偏好反应是通过某些渠道收集并记录在反馈库中的。这些被称作注释或反馈的相互作用和物品的相关描述一起被用在模型学习的过程中，这些信息对实际中预测新的相关物品的表示非常有用。因此，即使没有提供任何反馈，用户也可以清晰地定义他们自己感兴趣的领域作为初始的个人信息。&emsp;&emsp;通常情况下，我们能够区分这两种类型的相关性反馈：正面的信息（用户喜欢的特征）和负面的信息（用户不感兴趣的特征）。两种不同的技术都能用来记录用户的反馈。当系统要求用户明确评价物品时，这项技术通常称作“显式反馈”；反之，则称作“隐式反馈”，由于反馈来自监控和分析用户的行为，所以它不需要任何活跃用户的参与。确切的评价能够表明用户对一个物品相关或感兴趣的程度。主要有三种方式来得到显式的相关性反馈： 喜欢/不喜欢：利用一个简单的二元化评分刻度，将物品分成“相关的”或“不相关的”两大类。 评分：经常用来评价物品的一个离散的数值刻度，详情参见文献。当然，标记化的评价也可以映射到数值刻度，如在Syskill&amp;Webert中一样，把用户对网页的评价划分为热门、一般、冷门。 评论：收集并展示单一物品的评论给用户，使其成为用户加快决策过程的一种方式。例如，在Amazon或eBay上，用户的反馈可以帮助其他用户判断一件物品是否被大众所接受。文本评论是有益的，但是这些评论也会对用户造成负担，因为她必须阅读和理解每条评论，并决定哪些评论是正面的哪些是负面的，以及这些评论的程度。文献从情感计算研究领域中提出的先进技术，使得基于内容的推荐系统能够自动执行这种分析。 1. 基于内容的推荐系统基于内容的推荐与基于协同过滤的推荐相比有以下优点： 用户独立性：基于内容的推荐仅使用当前用户提供的评分来构建自己的个人信息。而协同过滤的方法需要其他用户的评分，来发现该用户最近的近邻，例如，由于对相同的物品评分相似而品味相似的用户。这时，只有当前用户最近邻很喜欢的物品才有可能推荐给当前用户。 透明度：通过显式地列出使得物品出现在推荐列表中的内容特征或描述，可以解释推荐系统是如何工作的。这些物品特征是决定是否信任该推荐的指标。相反，协同过滤系统是一个黑盒子，对一个推荐物品的唯一解释是相似品味的未知用户喜欢过该物品。 新物品：基于内容的推荐系统在没有任何用户评分的情况下也可以进行推荐。因此，新物品没有第一次评分会影响协同过滤推荐系统，因为协同过滤推荐系统仅依赖于用户的偏好产生推荐。所以只有当一个新物品被一系列用户评分之后，系统才可能推荐它。尽管如此，基于内容的推荐系统也有以下一些缺点： 可分析的内容有限：基于内容的推荐技术有一个天然的限制，即与推荐对象相关的特征数量和类型上的限制，不管是自动还是手动的。领域知识一般是必需的，例如，对于电影推荐，系统需要知道电影的演员、导演，有时候领域本体也是需要的。当分析的物品内容信息不足以区分哪些物品是用户喜欢的、哪些物品是用户不喜欢的时候，没有任何基于内容的推荐系统可以给出合适的推荐。有些解释只能获取物品内容的某些方面，但是还有很多别的方面也能影响用户体验。举个例子，在玩笑或者诗词里，没有足够的词频信息去为用户兴趣建模，这时，情感计算的技术就会更适用。此外，对于网页来说，文本特征抽取技术完全忽略其美学特征和附加的多媒体信息。总之，不论是手动还是自动为物品分配特征，都不足以定义物品不同的特点，而这些特点被证明对提取出用户兴趣是必要的。 过度特化：基于内容的推荐在本质上无法发现一些出人意料的物品。系统建议的物品和用户的个人信息高度匹配的时候，给用户的推荐也将会是与已有的评分物品相似的物品。这个缺点主要是由于基于内容的系统产生的推荐物品在新颖性上的缺陷，称作惊喜度问题。举例来说，当一个用户只评价了Stanley Kubrick导演的电影，那么她得到的推荐就只有这种类型的电影。一个“完美”的基于内容的技术可能很少发现任何新颖的东西，这限制了使用它的应用程序的范围。 新用户：在一个基于内容的推荐系统可以真正理解用户偏好且给出准确的推荐之前，需要收集足够的评分。因此，当只有很少的评分可用的时候，即对于新用户来说，系统不能提供可靠的推荐。接下来，将就采用何种策略来处理对上面提出的问题，进行介绍和讨论。更具体地，会阐述利用常识和特定领域的知识来提高内容解释的新技术。通过提供新的特征可能有助于克服传统的内容分析方式的限制，如 WordNet 或 Wikipedia 概念，帮助物品用一种更准确透明的方式进行推荐。此外，将推荐过程中用户定义词典，如大众分类，作为扩展词表加入考虑并进行整合的过程，使用惊喜度推荐，即新颖性很高的用户感兴趣的物品，来满足用户的可能方式将作为解决过度特化问题的解决方案进行分析。 3. 补充&emsp;&emsp;本篇文章只是大概写一下关于内容推荐的系统，具体的算法没有提及，日后有时间的话会不断的补充，最主要的一点是敲公式太麻烦了，此外还有基于情景感知的推荐系统以及基于约束的推荐系统日后应该不会提及，有兴趣的同学可以看一下《推荐系统：技术、评估及高效算法》，下一篇着重讲一下推荐系统中的数据挖掘方法。]]></content>
  </entry>
  <entry>
    <title><![CDATA[基于近邻推荐方法综述]]></title>
    <url>%2F2018%2F07%2F01%2F1%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;本文主要是对推荐系统中常用的常用算法的适用性以及优劣做一个总结，以让自己有一个更加清晰的认识，不会涉及公式以及算法的实现。 1 基于近邻推荐方法综述&emsp;&emsp;基于领域的推荐方法中主要包括了两种著名的推荐方法：基于用户的推荐和基于物品的推荐。在基于用户的推荐系统中，目标用户对某一物品的感兴趣程度是利用对该物品的历史评分，并且和目标用户有相似评分模式的其他用户来估计的。这里的目标用户的近邻是指与目标用户评分模式很一致的用户。基于物品的推荐系统，是根据某一用户对相似于目标物品的评分来预测该用户对目标物品的评分。在这种方法中，相似物品指那些被同一组用户评分并且评分值相近的物品。 2 基于近邻的两种推荐方法&emsp;&emsp;基于领域的推荐系统是根据相同的“口碑”的准则，根据和用户兴趣相同的人或者根据其他可信源来评价一个物品。 2.1 基于用户和基于物品的推荐方法的比较&emsp;&emsp;当需要选择是基于用户还是基于物品的推荐方法来实现推荐系统的时候，有5个准则需要考虑： 准确性 : 推荐系统的准确度很大程度依赖于系统中用户数和物品数之间的比例。通常，一小部分高可信度的用户要比一大部分相似度不是那么可信的近邻要合适的多，对于用户数量远远大于物品数量的大型商业系统，基于物品的推荐西永更加准确。同样对于用户数少与物品的推荐系统来说，可能采用基于用户的推荐系统更加准确。 效率：当用户数量远远大于物品数量时，基于物品推进方法在计算相似度权重方面所需的内存和时间要远远小于基于用户的方法，但是在线推荐阶段的时间复杂度因为只依赖于有效的物品和近邻数量的最大值，所以两者是相同的。 稳定性 稳定性主要取决于用户或者物品的改变频率和数量。 合理性 基于物品的推荐方法优点是容易证明推荐的合理性。基于用户的推荐系统就很难坐到这一点，因为用户不认识在在推荐结果中起到近邻作用的其他用户。 惊喜度 基于用户的推荐方法是根据用户的相似度来进行的，因此更有可能生成较为新颖的推荐结果，当推荐是基于很小部分近邻数更为有效。2.2 基于近邻方法的要素&emsp;&emsp;在近邻推荐系统中除了选择基于物品还是用户的推荐方法还存在一些重要属性比如:1)标准化评分;2)相似权重的计算;3)近邻的选择。2.2.1 评分标准化&emsp;&emsp;当一个用户对一个物品给予评分的时候，每个用户都有自己的评价准则。即使显示地定义每个评分的意义，有些用户依然不情愿给他们呢的物品评高分或者给他们不喜欢的物品评低分。均值中心化和Z-socre标准化可以将个人评分标准转换到更一般的整体评分标准。 均值中心化：通过与平均分的比较来决定一个评分为正或者负。 Z-score标准化：考虑个人评分范围不同带来的差异性。比如：用户 A 和用户 B 平均评分都是3，但是假设用户 A 的评分在1-5之间，用户 B 都是3。如果用户 B 给物品评5分，这会比用户 A 给物品5分更加以意外。因此反映了用户 B 更加喜欢这个物品。&emsp;&emsp;对比两者，Z-score在处理范围很大的离散评分或者连续值评分时更有优势。2.2.2 相似度权重的计算&emsp;&emsp;相似度权重计算在基于领域的推荐方法中扮演者重要的角色:1)可以选择可信的近邻用户用于评测评分；2）给予不同近邻在预测中的权重。计算相似度权重是基于近邻推荐系统中最重要的一个方面，他可以直接影响准确性和性能。具体的相似度计算方法本文略过，我们平常使用的余弦相似度扩展一下都可以。2.2.2 领域的选择2.2.2.1 领域的选择&emsp;&emsp;在大型的推荐系统中，由于硬件资源的限制，它不太可能存储所有的非零相似度。我们可以通过下边的方法来进行限制。 top-N过滤 阈值过滤 负值过滤2.2.2.2 用于预测的近邻&emsp;&emsp;一旦计算出每个用户或者物品的候选近邻列表，对一个新的评分预测可以通过k近邻方法得到，K 近邻也就是相似度权重对打的K个近邻。最重要的问题就是如何选择 K 值。&emsp;&emsp;K值的增加通常呈现出一个凸函数。因此当近邻数目限制一个很小的数的时候，预测度通常会低。当 K 很大的时候，一些重要的关联被一些不重要的关联所削弱。如何选择一个最优 K 值是我们优先考虑的问题。2.3 基于近邻的推荐方法优化&emsp;&emsp;基于近邻的推荐方法依然存在缺点： 覆盖受限：由于计算两个用户间的相似是基于他们对相同物品的评分，而且只有对相同物品进行评分的用户才可以作为近邻，所以覆盖受限。 对稀疏数据敏感：稀疏性是大多数推荐熊面临的共同问题，尤其面对冷启动问题，稀疏性更加严重。&emsp;&emsp;本文在这里列举两个方法，具体的方法和实现可以查阅相关文献: 基于图的方法 基于学习的方法]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[算法之路-常见字符串处理总结]]></title>
    <url>%2F2018%2F06%2F01%2F1%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;字符串处理是算法中比较重要的一部分。在本篇中，主要介绍一系列常见并且重要的字符串处理算法。 1.1 易位构词 定义&emsp;&emsp;如果对调字符，使得单词 w 变成单词 v，那么 w 就是 v 的易位构词。输入一个集合包含n个最大长度为 k 的单词，输出找到所有的易位构词。&emsp;&emsp;输入: &quot;le chien marche vers sa niche et trouve une limace de chine nue pleine de malice qui lui fait du charme&quot;&emsp;&emsp;输出: [&#39;chine&#39;, &#39;niche&#39;, &#39;chien&#39;], [&#39;marche&#39;, &#39;charme&#39;], [&#39;nue&#39;, &#39;une&#39;], [&#39;limace&#39;, &#39;malice&#39;] 算法思想&emsp;&emsp;思路比较简单，对每个单词进行排序，排序相同的放在一起。值得提醒的是，如果两个单词相同，则不是易构单词。 代码实现1234567891011121314def anagrams(w): w = list(set(w.split())) #分割删除重复项 d = &#123;&#125; for i in range (len(w)): #相同标签的单词序号保存在一起 s = "".join(sorted(w[i])) if s in d: d[s].append(i) else: d[s] = [i] reponse = [] for s in d: #输出易位单词 if len(d[s]) &gt; 1: reponse.append([w[i] for i in d[s]]) return reponse 1.2 KMP算法&emsp;&emsp;KMP算法可以说是一个很经典的算法，我们在日常编程中也经常会用到，KMP算法用来解决一系列字符串单模式匹配问题以及延伸出来的最大边KMP算法等等。 定义&emsp;&emsp;给定一个长度为 n 的字符串 s 和一个长度为 m 的待匹配模式字符串 t ，我们希望找到 t 在 s 中第一次出现的下标 i 。当 t 不是 s 的子串时，返回 -1。&emsp;&emsp;复杂度 O(n+m) 算法思想&emsp;&emsp;具体的算法思路可以参考这篇博客KMP算法详解。KMP算法主要是分为两个部分，第一部分计算模式字符串的 next 。第二部分计算字符串匹配。下边代码我们把两部分放在一个函数中。 代码实现1234567891011121314151617181920212223242526def kmp(s,p): len_s = len(s) len_p = len(p) next = [0] * len_p next[0] = -1 k = -1 j = 0 while j &lt; len_p-1: if k == -1 or p[j] == p[k]: j += 1 k += 1 next[j] = k else: k = next[k] i = 0 j = 0 while i &lt; len_s and j &lt; len_p: if j == -1 or s[i] == p[j]: i += 1 j += 1 else: j = next[j] if j == len_p: return i - j else: return -1 模式匹配算法除了KMP算法之外，还有Rabin-Karp算法，有时间的话会加上Rabin-Karp算法，Rabin-Karp算法时间复杂度一般也为 O(n) 。 1.3 回文字符： Manacher 算法&emsp;&emsp;manacher算法，我们习惯叫他 “马拉车”算法。&emsp;&emsp;Manacher算法的应用范围比较狭窄，但是它的思想和拓展kmp算法有很多共通之处，所以在这里介绍一下。Manacher算法是查找一个字符串的最长回文子串的线性算法。&emsp;&emsp;首先介绍一下什么是回文串，所谓回文串，简单来说就是正着读和反着读都是一样的字符串，比如abba，noon等等，一个字符串的最长回文子串即为这个字符串的子串中，是回文串的最长的那个。&emsp;&emsp;计算字符串的最长回文字串最简单的算法就是枚举该字符串的每一个子串，并且判断这个子串是否为回文串，这个算法的时间复杂度为O(n3)的，显然无法令人满意，稍微优化的一个算法是枚举回文串的中点，这里要分为两种情况，一种是回文串长度是奇数的情况，另一种是回文串长度是偶数的情况，枚举中点再判断是否是回文串，这样能把算法的时间复杂度降为O(n2)，但是当n比较大的时候仍然无法令人满意，Manacher算法可以在线性时间复杂度内求出一个字符串的最长回文字串。 定义&emsp;&emsp;如果字符串的第一个字符等于最后一个字符，而第二个字符又等于倒数第二个字符，以此类推，那么该字符就是一个回文字符串，“最长回文字串”就是要找到一个最长字串，其中字串是一个回文字串。&emsp;&emsp;输入:aaaabcdefgfedcbaa&emsp;&emsp;输出: aabcdefgfedcbaa 算法思想&emsp;&emsp;1.预处理字符串，将字符串处理为奇数，并且防止越界给字符串两边加上不同符号。&emsp;&emsp;2.对于位置 i 我们有三种情况处理，算法详情点击马拉车算法&emsp;&emsp;3.第三步就可以愉快的写代码。 代码实现12345678910111213141516def manachers(s): if s == &quot;&quot;: return (0,1) t = &quot;^#&quot; + &quot;#&quot;.join(s) + &quot;#$&quot; id_cent = 0 mx = 0 p = [0] * len(t) for i in range(1,len(t)-1): mirror = 2 * id_cent -i p[i] = max(0, min(p[mirror],mx-i)) while t[i + 1 + p[i]] == t[i - 1 - p[i]]: p[i] += 1 if i + p[i] &gt; mx: mx,id_cent, = i + p[i],i (k,i) = (max(p),p.index(max(p))) return (s[(i-k) // 2 :(i+k) //2]) 1.4小结&emsp;&emsp;字符串的处理我只记录了这三种，相对来说马拉车算法比较难理解。其他形式字符串的处理基本都是基于这些进行变化，比如:最长字串，最长公共字串等等。后续如果有时间，会继续在本文中更新Rabin-Karp算法。碰到有意思的字符串算法题也会继续更新。]]></content>
      <categories>
        <category>算法之路</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>算法</tag>
        <tag>字符串</tag>
        <tag>易位构词</tag>
        <tag>KMP算法</tag>
        <tag>回文字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统思维导图与架构]]></title>
    <url>%2F2018%2F05%2F06%2F1%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;本文主要是对《推荐系统技术 评估及高效算法》以及《推荐系统实战》两本书的总结，在后续的文章中会逐渐补充详细内容。 1. 推荐系统思维导图梳理 2. 推荐引擎架构&emsp;&emsp;推荐引擎使用一种或几种用户特征，按照一种推荐策略生成一种类型物品的推荐列表。 推荐系统引擎框架主要分为三个部分： A部分负责从数据库或者缓存中拿到用户行为数据，通过分析不同行为，生成当前用户的特征向量。不过如果是使用非行为特征，就不需要使用行为提取和分析模块了。该模块的输出是用户特征向量。 B部分负责将用户的特征向量通过特征-物品相关矩阵转化为初始推荐物品列表。 C部分负责对初始的推荐列表进行过滤、排名等处理，从而生成最终的推荐结果。 推荐引擎架构图 &emsp;2.1 生成用户特征向量&emsp;&emsp;一般来说，用户的特征包括两种，一种是用户的注册信息中可以提取出来的，主要包括用户的人口统计学特征。对于使用这种特征的推荐引擎，如果内存够，可以将存储这些特征的信息直接缓存在内存中，在推荐时直接拿到用户的特征数据并生成特征向量。除了这种特征，另一种特征主要是从用户的行为中计算出来的，本节着重讨论如何生成特征。&emsp;&emsp;一个特征向量由特征以及特征的权重组成，在利用用户行为计算特征向量时需要考虑以下因素。&emsp;&emsp;用户行为的种类 &emsp;在一个网站中，用户可以对物品产生很多不同种类的行为。用户可以浏览物品、单击物品的链接、收藏物品、给物品打分、购买物品、评论物品、给物品打上不同的标签、和好友分享物品、搜索不同的关键词等。这些行为都会对物品特征的权重产生影响，但不同行为的影响不同，大多时候很难确定什么行为更加重要，一般的标准就是用户付出代价越大的行为权重越高。比如，购买物品需要用户掏钱，所以用户一定会三思而后行，因此购买行为最为重要。相反，浏览物品的网页代价很小，所以这种行为对反映用户的真实兴趣的影响很小。&emsp;&emsp;用户行为产生的时间&emsp;一般来说，用户近期的行为比较重要，而用户很久之前的行为相对比较次要。因此，如果用户最近购买过某一个物品，那么这个物品对应的特征将会具有比较高的权重。&emsp;&emsp;用户行为的次数&emsp;有时用户对一个物品会产生很多次行为。比如用户会听一首歌很多次，看一部电视剧的很多集等。因此用户对同一个物品的同一种行为发生的次数也反映了用户对物品的兴趣，行为次数多的物品对应的特征权重越高。&emsp;&emsp;物品的热门程度&emsp;如果用户对一个很热门的物品产生了行为，往往不能代表用户的个性，因为用户可能是在跟风，可能对该物品并没有太大兴趣，特别是在用户对一个热门物品产生了偶尔几次不重要的行为（比如浏览行为）时，就更说明用户对这个物品可能没有什么兴趣，可能只是因为这个物品的链接到处都是，很容易点到而已。反之，如果用户对一个不热门的物品产生了行为，就说明了用户的个性需求。因此，推荐引擎在生成用户特征时会加重不热门物品对应的特征的权重。 &emsp;2.2 特征—物品相关推荐&emsp;&emsp;对于每个特征，我们可以在相关表中存储和它最相关的N个物品的ID。在线使用的特征-物品相关表一般都不止一张。以论文之间的相关表为例，计算论文之间的相关性既可以使用提出的协同过滤算法（即如果两篇论文的读者重合度很大说明两部电视剧相似），也可以通过内容计算（比如有相同的作者、关键词、相似的标题等）。即使是协同过滤，也可以根据不同的用户行为数据得到不同的相关表。比如可以根据用户的打分行为计算论文之间的相关性，也可以根据用户的浏览行为计算论文之间的相关性。总之，对于一个推荐引擎可以在配置文件中配置很多相关表以及它们的权重，而在线服务在启动时会将这些相关表按照配置的权重相加，然后将最终的相关表保存在内存中，而在给用户进行推荐时，用的已经是加权后的相关表了。&emsp;&emsp;从上面的架构图可以看到，特征—物品相关推荐模块还可以接受一个候选物品集合。候选物品集合的目的是保证推荐结果只包含候选物品集合中的物品。它的应用场合一般是产品需求希望将某些类型的电视剧推荐给用户。比如有些产品要求给用户推荐最近一周加入的新物品，那么候选物品集合就包括最近一周新加的物品。也许有读者会奇怪，为什么不在过滤模块中将候选集合外的电视剧过滤掉，而要在相关推荐模块中处理候选物品列表？这里举一个简单的例子说明原因。首先，一般来说对于协同过滤算法计算出的相关表，每个物品都会倾向于和比较热门的物品具有较高的相似度。那么假设用户购买过物品A，候选列表中包含了物品B，A和B相关，但A比B热门。那么，一般情况下，B在A的相关物品列表中会排在靠后的位置（假设排在第10名），而A在B的相关物品列表中会排在靠前的位置（假设排在第1名）。那么，如果推荐算法是给用户推荐和A最相关的5部电视剧，那么B就不会出现在用户的推荐列表中。但是，如果算法在给定候选列表时会用一种不同的方式进行推荐，比如如果用户看过和B最相关的5部电视剧中的某一部，就将B推荐给用户，那么这种情况下B就出现在推荐列表中了。&emsp;&emsp;一般来说，如果需要在一个小的候选物品集合中给用户推荐物品，那么可以考虑上述方法。但如果是要在一个很大的候选物品集合中给用户推荐物品，那么可以考虑直接在初始推荐列表中过滤掉不在候选物品集合中物品的方法。&emsp;&emsp;特征—物品相关推荐模块除了给用户返回物品推荐列表，还需要给推荐列表中的每个推荐结果产生一个解释列表，表明这个物品是因为哪些特征推荐出来的。 &emsp;2.3 过滤模块&emsp;&emsp;在得到初步的推荐列表后，还不能把这个列表展现给用户，首先需要按照产品需求对结果进行过滤，过滤掉那些不符合要求的物品。一般来说，过滤模块会过滤掉以下物品。&emsp;&emsp;用户已经产生过行为物品&emsp;因为推荐系统的目的是帮助用户发现物品，因此没必要给用户推荐他已经知道的物品，这样可以保证推荐结果的新颖性。&emsp;&emsp;候选物品以外的物品 &emsp;候选物品集合一般有两个来源，一个是产品需求。比如在首页可能要求将新加入的物品推荐给用户，因此需要在过滤模块中过滤掉不满足这一条件的物品。另一个来源是用户自己的选择，比如用户选择了某一个价格区间，只希望看到这个价格区间内的物品，那么过滤模块需要过滤掉不满足用户需求的物品。&emsp;&emsp;某些质量很差的物品 为了提高用户的体验，推荐系统需要给用户推荐质量好的物品，那么对于一些绝大多数用户评论都很差的物品，推荐系统需要过滤掉。这种过滤一般以用户的历史评分为依据，比如过滤掉平均分在2分以下的物品。 &emsp;2.4 排名模块&emsp;&emsp;经过过滤后的推荐结果直接展示给用户一般也没有问题，但如果对它们进行一些排名，则可以更好地提升用户满意度，一般排名模块需要包括很多不同的子模块，下面将对不同的模块分别加以介绍。 新颖性 多样性 时间多样性 用户反馈]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
        <tag>思维导图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云计算基础知识]]></title>
    <url>%2F2018%2F05%2F01%2F1%2F</url>
    <content type="text"><![CDATA[云计算概念云计算是一种按使用量付费的模式，这种模式提供可用的、便捷的、按需的网络访问，进入可配置的计算资源共享池（资源包括网络，服务器，存储，应用软件，服务），这些资源能够被快速提供，只需要投入的管理工作，或与服务供应商进行很少的交互。 云的4种模式 公有云:是现在最主流也就是最受欢迎的云计算模式。它是一种对公众开放的云服务，能支持数目庞大的请求，而且因为规模的优势，其成本偏低。公有云由云供应商运行，为最终用户提供各种各样的IT资源。云供应商负责从应用程序、软件运行环境到物理基础设施等IT资源的安全、管理、部署和维护。在使用IT资源时，用户只需为其所使用的资源付费，无需任何前期投入，所以非常经济，而且在公有云中，用户不清楚与其共享和使用资源的还有其他哪些用户，整个平台是如何实现的，甚至无法控制实际的物理设施，所以云服务提供商能保证其所提供的资源具备安全和可靠等非功能性需求。 私有云：主要为企业内部提供云服务，不对公众开放，在企业的防火墙内工作，并且企业IT人员能对其数据、安全性和服务质量进行有效地控制。与传统的企业数据中心相比，私有云可以支持动态灵活的基础设施，降低IT架构的复杂度，使各种IT资源得以整合和标准化。 混合云：混合云虽然不如前面的公有云和私有云常用，但已经有类似的产品和服务出现。顾名思义，混合云是把公有云和私有云结合到一起的方式，即它是让用户在私有云的私密性和公有云灵活的低廉之间做一定权衡的模式。比如，企业可以将非关键的应用部署到公有云上来降低成本，而将安全性要求很高、非常关键的核心应用部署到完全私密的私有云上。 行业云：行业云与公众云的主要区别在于数据来源及服务提供者的的核心竞争力。公众云是可为公众所使用的云平台，一般为一个专门出售云服务的机构所拥有，例如google、baidu，其特点是数据来源是公开途径，通过独有的应用为利用公开数据为客户提供服务，其算法、业务系统是其核心竞争力；而行业云的数据主要来源于行业内部的核心组织，也有一部分会来自行业内部的其他成员，绝大部分是私有数据，数据是其核心竞争力，因此，数据不可能提供给第三方却又同时具有对外服务的需求。如未来质检行业需要对外提供各类商品的信息查询，但是数据又不可能交给第三方处理，所以质监系统会建立一个质检行业云，整合整个系统的信息，来对外提供该类服务，类似的行业还有交通、环保、卫星等。云计算架构 云计算特性 基于互联网络：云计算是通过把一台台的服务器连接起来，使服务器之间可以相互进行数据传输，数据就像网络上的“云一样”在不同服务器之间 “飘”。同时通过网络向用户提供服务。 按需服务：“云”的规模是可以动态伸缩的。在使用云计算服务的时候，用户所获得的计算机资源是按用户个性化需求增加或减少的，并在此基础上对自己的使用的服务进行付费的。 资源池化:资源池是对各种资源（如存储资源，网络资源）进行统一配置的一种配置机制。从用户角度看，无需关心设备型号，内部的复杂结构，实现的方法和地理位置，只需关心自己需要什么服务即可。从资源的管理者角度来看，最大的好处是资源池可以近乎无限地增减和更换设备，并且管理，调度资源十分便捷。 安全可靠:云计算必须要保证服务的可持续性、安全性、高效性和灵活性。故对于提供商来说，必须采用各种冗余机制、备份机制、足够安全的管理机制和保证存取海量数据的灵活机制等，从而保证用户的数据和服务安全可靠。对于用户来说，其只要支付一笔费用，即可得到供应商提供的专业级安全防护，节省大量时间与精力。 资源可控:云计算提出的初衷，是让人们可以像使用水电一样便捷的使用云计算服务，极大的方便人们获取计算服务资源，并大幅度提供计算资源的使用率，有效节约成本，使得资源在一定程度上属于“控制范畴”。但如何对云计算服务进行合理的、有效的计费，仍是一项值得业界关注的课题。]]></content>
      <categories>
        <category>AI时代</category>
      </categories>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scikit-learn机器学习之K-近邻算法]]></title>
    <url>%2F2018%2F03%2F14%2F1%2F</url>
    <content type="text"><![CDATA[k－近邻算法 它是一个有监督的机器学习算法。近邻算法也称为 Knn 法，可以解决分类问题，也可以解决回归问题。 ##算法原理K－近邻算法的核心思想是未标记样本的类别，由距离其最近 个邻居投票来决定。假设，我们有一个已经标记的数据集，即己经知道了数据集中每个样本所属的类别此时，有一个未标记的数据样本，我们的任务是预测出这个数据样本所属的类别 ，近邻算法的原理是，计算待标记的数据样本和数据集中每个样本的距离，取距离最近的 k 个样本。待标记的数据样本所属的类别，就由这 k 个距离 近的样本投票产生。假设 test数据集 待标记的数据样本， train数据集为己标记的数据集，算法原理的伪代码如下： 遍历 train 中的所有样本，计算每个样本与 test 的距离，并且把距离保存在 Distance 数组中。 对 Distance 数组进行排序，取距离最近的K个点，为X_Knn。 在 X_knn 中统计每个类别的数量。比如 class 0 在 X_Knn 中几个样本等。 待标记样本的类别，就是在X_knn中样本个数最多的那个。##算法优缺点优点：准确性高，对异常值和 噪声有较高的容忍度缺点：计算量较大，对内存的需求也较大。从算法原理可以看出来，每次对一个未标记样本进行分类时，都需要全部计算遍距离。 算法参数其算法参数是k, 参数选择需要根据数据来决定。k 值越大，模型的偏差越大，对噪声数据越不敏感，当 k 值很大时 可能造成模型欠拟合，k 值越小，模型的方差就会越大，当k 值太小， 就会造成模型过拟合。 算法的变种k-近邻算法有一些变种，其中之一就是可以增加邻居的权重。默认情况下，在计算距离时，都是使用相同权重。实际上，我们可以针对不同的邻居指定不同的距离权，如距离越近权重越高。这个可以通过指定算法的 weights 参数来实现。另外一个变种是使用一定半径内的点取代距离最近的k个点。在 sc ikit-learn 中 RadiusNeighborsClassifier 类实现了这个算法的变种。当数据采样不均匀时 该算法变种可以取得更好的性能 sklearn中的Knn生成已经标记的数据12345678910111213%matplotlib inlineimport matplotlib.pyplot as pltimport numpy as npfrom sklearn.datasets.samples_generator import make_blobscenters = [[-2, 2], [2, 2], [0, 4]]X, y = make_blobs(n_samples=60, centers=centers, random_state=0, cluster_std=0.60)plt.figure(figsize=(16, 10))c = np.array(centers)plt.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=&apos;cool&apos;); plt.scatter(c[:, 0], c[:, 1], s=100, marker=&apos;^&apos;, c=&apos;orange&apos;); 代码解读 1-4行导入所需要的包 6行设置中心点数据 7行使用 make_blobs 生成数据集。生 60 个训练样本，这 60 样本分布在以 centers 参数指定中心点周围。cluster std 是标准差，用来指明生成的点分布的松散程度。生成的训练数据集 X 放在变量里面，数据集的类别标记放在Y里面 12行画出样本，具体的画图操作以及参数前几天有篇博文讲到了 13行画出中心点使用 KNeighborsC lassifier 进行预测123456789101112131415161718192021from sklearn.neighbors import KNeighborsClassifier# 模型训练k = 5clf = KNeighborsClassifier(n_neighbors=k)clf.fit(X, y);# 进行预测X_sample = [0, 2]X_sample = np.array(X_sample).reshape(1, -1)y_sample = clf.predict(X_sample);neighbors = clf.kneighbors(X_sample, return_distance=False);# 画出示意图plt.figure(figsize=(16, 10))plt.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=&apos;cool&apos;) # 样本plt.scatter(c[:, 0], c[:, 1], s=100, marker=&apos;^&apos;, c=&apos;k&apos;) # 中心点plt.scatter(X_sample[0][0], X_sample[0][1], marker=&quot;x&quot;, s=100, cmap=&apos;cool&apos;) # 待预测的点for i in neighbors[0]: # 预测点与距离最近的 5 个样本的连线 plt.plot([X[i][0], X_sample[0][0]], [X[i][1], X_sample[0][1]], &apos;k--&apos;, linewidth=0.6); 从图中我们也可以看到K-近邻算法的原理 总结前边写了KNN的分类问题，之前我们说过KNN还可以用于回归问题，如果有兴趣可以自己搞一下。进行回归拟合的算法是 sklearn.neighbors.KNeighborsRegressor 类。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>scikit-learn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习查准率和召回率]]></title>
    <url>%2F2018%2F03%2F12%2F1%2F</url>
    <content type="text"><![CDATA[查准率和召回率在机器学习中，我把查准率和召回率使用单独的一篇博客讲一下。在上文中我们说到了模型的准确性。但是有时候，模型的准确性并不能评价一个算法的好坏。我们举一个例子，普通肿瘤中癌症的概率是 0.5% 。有个机器学习算法，测试得出的准确率是 99.2% ，错误率0.8% 。这个算法到底是好还是坏呢？如果努力改进算法，最终得出的准确率是 9.5%,错误率是 0.5%，模型到底是变好了还是变坏了呢？那么怎么评价这类问题的模型好坏呢，我们有两个概念。查准率和召回率。| &nbsp; | 实际正样本 | 实际负样本 || :——–: | :—–: | :—-: || 预测正样本 | TruePositive | FalsePositive || 预测负样本 | FalseNegative | TrueNegative |我们对上边的表格中的名次进行一下解释：TruePositive（真正）： 正样本预测为正样本的数量FalsePositive（假正）： 负样本预测为正样本的数量FalseNegative（假负）： 正样本预测为负样本的数量TrueNegative(真负)： 负样本预测为负样本的数量了解基本概念后，我们再看一下查准率和召回率查准率是针对我们预测结果而言的，它表示的是预测为正的样本中有多少是真正的正样本。那么预测为正就有两种可能了，一种就是把正类预测为正类(TP)，另一种就是把负类预测为正类(FP)，也就是$$查准率 = \frac {TP} {TP + FP}$$而召回率是针对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确了。那也有两种可能，一种是把原来的正类预测成正类(TP)，另一种就是把原来的正类预测为负类(FN)。$$召回率 = \frac {TP} {TP + FN}$$ F1 Score由于现在有两个指标一查准率和召回率，如果有一个算法的查准率是 0.5 ，召回率是业另外 个算法查准率是 0.02 ，召回率是 1.0 那么两个算法到底哪个好呢？为了解决这个问题，我们有 F1Score ：$$F_1Score =2 \frac {PR} {P + R}$$其中 p 是查准率， R是召回率。这样就可以用 个数值直接判断哪个算法性能更好。典型地，如果查准率或召回率有一个为 0 ，那么 F1Score 将会为 0。而理想的情况下，查准率和召回率都为1算出来的 $F_1Score$也是就1。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习基础概念（二）]]></title>
    <url>%2F2018%2F03%2F12%2F1%2F</url>
    <content type="text"><![CDATA[过拟合和欠拟合过拟合是指模型能很好地拟合训练样本，但对新数据的预测准确性很差。欠拟合是指模型不能很好地拟合训练样本，且对新数据的预测准确性也不好。如下图：注释:本文中的图形可视化使用的书中的参考代码，有部分做了更改，建议大家有时间可以读一下《scikit-learn机器学习：常用算法原理及编程实战》左边是欠拟合（ underfitting ），也称为高偏差（ high bias ），因为我们试图用一条直线来拟合样本数据。右边是过拟合（ overfitting ），也称为高方差（ high variance) 用了十阶多项式来 合数据，虽然模型对现有的数据集拟合得很好，但对新数据预测误却很大。只有中间的模型较好地拟合了数据集，可以看到虚线和实线基本重合。 成本函数成本是衡量模型与训练样本符合程度的指标。简单地理解，成本是针对所有的训练样本，模型拟合出来的值与训练样本的真实值的误差平均值 而成本函数就是成本与模型参数的函数关系。模型训练的过程，就是找出合适的模型参数，使得成本函数的值最小。成本函数记为 $J(\theta)$ 其中 $\theta$ 表示模型参数我们用一阶多项式来拟合数据，则得到的模型是 $y＝\theta_0+\theta_1x$，其中$\theta_0,\theta_1$构成的向 就是模型参数,训练这个模型的目标，就是找出合适的模型参数，使得所有的点到这条直线上的距离最短。根据成本函数的定义，我们可以很容易得出模型的成本函数公式：$$J \left ( \theta\right )= \frac{1}{2m}\sum_{i=1}^{m}\left ( h_{\theta }\left ( x^{\left ( i \right )} \right )-y^{\left ( i \right )} \right )^{2}$$其中， $m$是训练样本个数，在我们的例子里，是 20 个点，而 $h（x^i）$ 就是模型对每个样本的预测值， $y^i$是每个样本的真实值 这个公式实际上就是线性回归算法的成本函数。在过拟合和欠拟合那里我们也清楚如果训练样本到曲线距离的平均值变小，也可能会产生过拟合现象。 模型准确性模型准确性的验证我们可以使用测试数据集的成本函数来评估，$J(\theta)$ 越小，我们的模型准确性就越高。 模型性能的不同表达方式在scikit-learn里，不使用成本函数来表达模型的性能，而使用分数来表达，这个分数总是在 [0,1] 之 间，数值越大说明模型的准确性越好。当模型训练完成后，调用模型score(X _test, y _test） 即可算出模型的分数值，其中 X_test和Y_test是测试数据集样本。模型分数（准确性〉与成本成反比即分数越大，准确性越高，误差越小，成本越低反之，分数越小，准确性越低，误差越大，成本越高。 交叉验证第一种是简单交叉验证，所谓的简单，是和其他交叉验证方法相对而言的。首先，我们随机的将样本数据分为两部分（比如： 70%的训练集，30%的测试集），然后用训练集来训练模型，在测试集上验证模型及参数。接着，我们再把样本打乱，重新选择训练集和测试集，继续训练数据和检验模型。最后我们选择损失函数评估最优的模型和参数。 第二种是S折交叉验证（S-Folder Cross Validation）。和第一种方法不同，S折交叉验证会把样本数据随机的分成S份，每次随机的选择S-1份作为训练集，剩下的1份做测试集。当这一轮完成后，重新随机选择S-1份来训练数据。若干轮（小于S）之后，选择损失函数评估最优的模型和参数。第三种是留一交叉验证（Leave-one-out Cross Validation），它是第二种情况的特例，此时S等于样本数N，这样对于N个样本，每次选择N-1个样本来训练数据，留一个样本来验证模型预测的好坏。此方法主要用于样本量非常少的情况，比如对于普通适中问题，N小于50时，我一般采用留一交叉验证。 学习曲线如果数据集的大小为m，则通过下面的流程即可画出学习曲线 把数据集分成训练数据集和交叉验证数据集。 取训练数据集的 20% 作为训练样本，训练出模型参数。 使用交叉验证数据集来计算训练出来的模型的准确性。 以训练数据集的准确性，交叉验证的准确性作为纵坐标，训练数据集个数作为横坐标，在坐标轴上画出上述步骤计算出来的模型准确性 训练数据集增加 10% ，跳到步骤 3 继续执行，直到训练数据集大小为 100%为止。 学习曲线要表达的内容是，当训练数据集增加时，模型对训练数据集拟合的准确性以及对交叉验证数据集预测的准确性的变化规律。 过拟合和欠拟合的特征 过拟合：模型对训练数据集的准确性比较高，其成本 $J(\theta)$ 比较低 对交叉验证数据集的准确性比较低 其成本 $J(\theta)$ 比较高。 欠拟合：模型对训练数据集的准确性比较低，其成本 $J(\theta)$较高，对交叉验证数则相反。 一个好的机器学习算法应该是对训练数据集准确性高、成本本低，即较准确地拟合数据，同时对交叉验证数据 准确性 、成本低、误 ，即对未知数据有良好的预测性。 算法模型性能优化过拟合: 获取更多的训练、数据 减少输入的特征数量 欠拟合： 增加有价值的特征 增加多项式特征查准率和召回率查准率和召回率在下一篇文章中会详细说一下。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习基础概念]]></title>
    <url>%2F2018%2F03%2F09%2F1%2F</url>
    <content type="text"><![CDATA[机器学习定义机器学习是一个计算机程序，针对某个特定的任务 从经验中学习，井且越做越好机器学习中的重要内容 数据： 定义中的从经验中学习，经验就指的是历史行为产生的海量数据，有质量高并且海量的数据，就占据了机器学习和人工智能领域最有利的资本。 模型： 模型就是我们用数据+算法得到的一个东西，是机器学习的核心。一个良好的训练模型，我们输入一个新事件时，会得到一个理想的结果。 机器学习应用人工智能普遍应用的产品或服务可分为三大类： 自然语言处理: 自然语言处理就是计算机对字、词、句、篇章的输入、输出、识别、分析、理解、生成等的操作和加工。实现人机间的信息交流。自然语言处理的具体表现形式包括机器翻译、文本摘要、文本分类、文本校对、信息抽取、语音合成、语音识别等。在我自己看的书里边有几本书把自然语言处理和语音识别分开来讲，其实语音识别就是自然语言处理的一个基本分支。 计算机视觉： 计算机视觉学所研究的对象,简单地说就是研究如何让计算机通过图象传感器或其它光传感器来感知、分析和理解周围环境。例如自动驾驶、医疗影像诊断 、机器人分拣、人脸识别等等。 大数据分析和预测： 我们常见的有交互搜索引擎、智能推荐引擎、金融风控 健康风险管理系统等。 机器学习分类监督学习(Supervised learning)通过大量已知的输入和输出相配对的数据，让计算机从中学习出规律从而能针对一个新的输入做出合理的输出预测。比如，我 有大不同特征（面积、地理位、朝向、开发商等〉的房子的价格数据，通过学习这些数据，预测一个己知特征的房子价格 这种称为 回归学习（Regressio learning），即输出结果是一个具体的数值，它的预测模型是一个连续的函数。再比如我们有大量的邮件 每个邮件都已经标记是否是垃圾邮件。通过学习这些己标记的邮件数据，最后得出一个模型，这个模型对新的邮件，能准确地判断出该邮件是否是垃圾邮件，这种称为 分类学习(Classfication learning ，即输出结果是离散的 即要么输出表示是垃圾邮件 要么输出表示不是垃圾邮件。 无监督学习(Unsupervised learning)通过学习大的无标记的数据，去分析出数据本身的内 在特点和结构。比如，有大量的用户购物的历史记录信息，从数据中去分析用户的不同类 。针对这个问题，我们最终能划分几个 类别？别有哪些特点？我们事先是不知道 。这个称为聚类（ Clustering）这里需要特别注意和有监督学习里的分类的区别，分类问题是我们已经知道了有哪几种类别；而聚类问题，是我们在分析数据之前其实是不知道有哪些类别的即分类问题是在己知答案里选择一个，而聚类问题的答案是未知的，需要利用算法从数据里挖掘出数据的特点和结构。 这两种机器学习类别的最大区别是，有监督学习的训练数据里有己知的结果来“监督”，而无监督学习的训练数据里没有结果“监督”，不知道到底能分析出什么样的结果。在我们日常的使用过程中，其实也可以使用人类自己的逻辑和经验进行分类，这样无监督学习也可以变成有监督学习。 机器学习开发步骤在吴恩达老师的机器学习课程中，有一门课讲的就是房价预测，我们可以根据吴恩达老师的这门课程来学习机器学习应用的开发步骤。 数据采集和标记我们需要大量不同特征的房子和所对应的价格信息，可以直接从房产评估中获取房子的相关信息，如房子的面积 地理位置、朝向、价格等另外还有这些信息房产评定有，比如房子所在 的学校情况，这特征往往会影响房子的价格，这个时候就需要通过其他途径收集这些数据，这些数据训练样本或数据集。房子的面积 地理位置等称为特征，在数据采集阶段，需要收集尽多的特征。特征越全，数据越多，出来的模型才会越准确。通过这个过程也可以感受到数据来集的成本可能是很高的。 数据清洗数据清洗过程中比如房子的面积，单位可能不统一，我们要进行统一，还有的数据有很多缺失项，我们应该选择一个合适的填充方式。还包括其他掉重复的数据及噪声数据，让数据具备结构化特征，以方便作为机器学习算法的输入。 特征选择我们采集到房子的特征项可能有很多，通过我们分析这些特征项，我们可以对一影响房价的特征项保留。这个过程就是特征选择。特征选择的方法之一就是人工选择。还有一种方法是通过模型来自动完成。 模型选择房价评估系统是属于有监督学习的回归学习类型，我们可以选择最简单的线性方程来进行计算。选择哪个模型和问题领域、数据大小、训练时长、模型的准确度等多方面有关系。 模型训练和测试把数据集分成训练集和测试数据集一般按照 8:2 或者 7:3 来划分 然后用训练数据集来训练模型，训练出来后再使用测试数据来测试模型的准确度。此外还加一个交叉验证数据集。 型性能评估和优化模型出来后，我们需要对机器习的算法模型进行性能评估性能评估包括很多方面：训练时长是指需要花多段时间来训练这些模型，对一些海量数据的机器学习应用，可能需要几个月甚至更长的时间来训练这个模型 这个时候算法的训练性能就变得很重要了另外，还需要判断数据集是否足够多，一般而言，对于复杂特征的系统，训练数据集越大越好。然后还需要判断模型的准确性，即对一个新的数据能否准确 进行预测。最后需要判断模型是否能满足应用场景的性能要求，如果不能满足要求，就需要优化，然后继续对模型进行训练和评估，或者更换为其他模型。 模型使用训练出来的模型可以把参数保存起来，下次使用时直接加载即可。 一般来讲，模型训练需要的计算量是很大的，也需要较长的间来训练，这是因为一 个好的模型参数，需要对大型数据集进行训练后才能得到。而真正使用模型时，其计算量是比较少的，一般是直接把新样本作为输入 然后调用模型即可得出预测结果。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python-plt.scatter参数详解]]></title>
    <url>%2F2018%2F03%2F07%2F1%2F</url>
    <content type="text"><![CDATA[准备自己写的时候，发现网上有一个总结挺好的。直接转载一下plt.scatter各参数详解]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python微信防撤回]]></title>
    <url>%2F2017%2F12%2F11%2F1%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;主要通过python微信库itchat，itchat可以实现很多有意思的够不够能比如:微信防撤回，微信红包提醒，微信机器人自动回复等。有关itcht的使用可以查看更多官方文档。下方代码实现了微信防撤回功能。 python3.6 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176import itchatimport sysimport timeimport reimport importlibimport osimportlib.reload(sys)from itchat.content import *msg_information = &#123;&#125;face_bug = None@itchat.msg_register([TEXT, PICTURE, FRIENDS, CARD, MAP, SHARING, RECORDING, ATTACHMENT, VIDEO], isFriendChat=True,isMpChat=True) def handle_receive_msg(msg): global face_bug msg_time_rec = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()) msg_from = itchat.search_friends(userName=msg['FromUserName'])['NickName'] msg_time = msg['CreateTime'] msg_id = msg['MsgId'] msg_content = None msg_share_url = None print(msg['Type']) print(msg['MsgId']) if msg['Type'] == 'Text' or msg['Type'] == 'Friends': msg_content = msg['Text'] print(msg_content) elif msg['Type'] == "Attachment" or msg['Type'] == "Video" \ or msg['Type'] == 'Picture' \ or msg['Type'] == 'Recording': msg_content = msg['FileName'] msg['Text'](str(msg_content)) elif msg['Type'] == 'Card': msg_content = msg['RecommendInfo']['NickName'] + '的名片' if msg['RecommendInfo']['Sex'] == 1: msg_content += '性别为男' else: msg_content += '性别为女' print(msg_content) elif msg['Type'] == 'Map': x, y, location = re.search( "&lt;location x=\"(.*?)\" y=\"(.*?)\".*label=\"(.*?)\".*", msg['OriContent']).group(1, 2, 3) if location is None: msg_content = r"纬度-&gt;" + x.__str__() + " 经度-&gt;" + y.__str__() else: msg_content = r"" + location elif msg['Type'] == 'Sharing': msg_content = msg['Text'] msg_share_url = msg['Url'] print(msg_share_url) face_bug = msg_content msg_information.update( &#123; msg_id: &#123; "msg_from": msg_from, "msg_time": msg_time, "msg_time_rec": msg_time_rec, "msg_type": msg["Type"], "msg_content": msg_content, "msg_share_url": msg_share_url &#125; &#125; ) @itchat.msg_register(NOTE, isFriendChat=True, isGroupChat=True, isMpChat=True)def information(msg): if '撤回了一条消息' in msg['Content']: old_msg_id = re.search("\&lt;msgid\&gt;(.*?)\&lt;\/msgid\&gt;", msg['Content']).group(1) old_msg = msg_information.get(old_msg_id) print(old_msg) if len(old_msg_id) &lt; 11: itchat.send_file(face_bug, toUserName=msg['FromUserName']) else: msg_body = "【" \ + old_msg.get('msg_from') + " 撤回了 】\n" \ + old_msg.get("msg_type") + " 消息：" + "\n" \ + old_msg.get('msg_time_rec') + "\n" \ + r"" + old_msg.get('msg_content') if old_msg['msg_type'] == "Sharing": msg_body += "\n就是这个链接➣ " + old_msg.get('msg_share_url') itchat.send_msg(msg_body, toUserName=msg['FromUserName']) if old_msg["msg_type"] == "Picture" \ or old_msg["msg_type"] == "Recording" \ or old_msg["msg_type"] == "Video" \ or old_msg["msg_type"] == "Attachment": file = '@fil@%s' % (old_msg['msg_content']) itchat.send(msg=file, toUserName=msg['FromUserName']) os.remove(old_msg['msg_content']) msg_information.pop(old_msg_id)@itchat.msg_register([TEXT, PICTURE, FRIENDS, CARD, MAP, SHARING, RECORDING, ATTACHMENT, VIDEO], isGroupChat=True)def handle_receive_msg(msg): global face_bug msg_time_rec = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()) msg_Actual_from = msg['ActualNickName'] msg_from = msg_Actual_from msg_time = msg['CreateTime'] msg_id = msg['MsgId'] msg_content = None msg_share_url = None print(msg['Type']) print(msg['MsgId']) if msg['Type'] == 'Text' or msg['Type'] == 'Friends': msg_content = msg['Text'] print(msg_content) elif msg['Type'] == "Attachment" or msg['Type'] == "Video" \ or msg['Type'] == 'Picture' \ or msg['Type'] == 'Recording': msg_content = msg['FileName'] msg['Text'](str(msg_content)) elif msg['Type'] == 'Card': msg_content = msg['RecommendInfo']['NickName'] + '的名片' if msg['RecommendInfo']['Sex'] == 1: msg_content += '性别为男' else: msg_content += '性别为女' print(msg_content) elif msg['Type'] == 'Map': x, y, location = re.search( "&lt;location x=\"(.*?)\" y=\"(.*?)\".*label=\"(.*?)\".*", msg['OriContent']).group(1, 2, 3) if location is None: msg_content = r"纬度-&gt;" + x.__str__() + " 经度-&gt;" + y.__str__() else: msg_content = r"" + location elif msg['Type'] == 'Sharing': msg_content = msg['Text'] msg_share_url = msg['Url'] print(msg_share_url) face_bug = msg_content msg_information.update( &#123; msg_id: &#123; "msg_from": msg_from, "msg_time": msg_time, "msg_time_rec": msg_time_rec, "msg_type": msg["Type"], "msg_content": msg_content, "msg_share_url": msg_share_url &#125; &#125; )@itchat.msg_register(NOTE, isGroupChat=True, isMpChat=True)def information(msg): if '撤回了一条消息' in msg['Content']: old_msg_id = re.search("\&lt;msgid\&gt;(.*?)\&lt;\/msgid\&gt;", msg['Content']).group(1) old_msg = msg_information.get(old_msg_id) print(old_msg) if len(old_msg_id) &lt; 11: itchat.send_file(face_bug, toUserName=msg['FromUserName']) else: msg_body = "【" \ + old_msg.get('msg_from') + " 群消息撤回提醒】\n" \ + " 撤回了 " + old_msg.get("msg_type") + " 消息：" + "\n" \ + old_msg.get('msg_time_rec') + "\n" \ + r"" + old_msg.get('msg_content') if old_msg['msg_type'] == "Sharing": msg_body += "\n就是这个链接➣ " + old_msg.get('msg_share_url') itchat.send_msg(msg_body, toUserName=msg['FromUserName']) if old_msg["msg_type"] == "Picture" \ or old_msg["msg_type"] == "Recording" \ or old_msg["msg_type"] == "Video" \ or old_msg["msg_type"] == "Attachment": file = '@fil@%s' % (old_msg['msg_content']) itchat.send(msg=file, toUserName=msg['FromUserName']) os.remove(old_msg['msg_content']) msg_information.pop(old_msg_id)itchat.auto_login(enableCmdQR=0, hotReload=True)itchat.run() 注：本文部分代码参考网络]]></content>
      <tags>
        <tag>python</tag>
        <tag>itchat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL性能优化]]></title>
    <url>%2F2017%2F11%2F20%2F1%2F</url>
    <content type="text"><![CDATA[1.项目中常用的MySQL优化方法1. EXPLAIN做MySQL优化，我们要善用EXPLAIN查看SQL执行计划。 type列，连接类型。一个好的SQL语句至少要达到range级别。杜绝出现all级别。 key列，使用到的索引名。如果没有选择索引，值是NULL。可以采取强制索引方式。 key_len列，索引长度。rows列，扫描行数。该值是个预估值。extra列，详细说明。注意，常见的不太友好的值，如下：Using filesort，Using temporary。 2. SQL语句中IN包含的值不应过多MySQL对于IN做了相应的优化，即将IN中的常量全部存储在一个数组里面，而且这个数组是排好序的。但是如果数值较多，产生的消耗也是比较大的。再例如：select id from t where num in(1,2,3) 对于连续的数值，能用between就不要用in了；再或者使用连接来替换。 3. SELECT语句务必指明字段名称SELECT*增加很多不必要的消耗（CPU、IO、内存、网络带宽）；增加了使用覆盖索引的可能性；当表结构发生改变时，前断也需要更新。所以要求直接在select后面接上字段名。4. 当只需要一条数据的时候，使用limit1这是为了使EXPLAIN中type列达到const类型5. 如果排序字段没有用到索引，就尽量少排序6. 如果限制条件中其他字段没有索引，尽量少用or or两边的字段中，如果有一个不是索引字段，而其他条件也不是索引字段，会造成该查询不走索引的情况。很多时候使用union all或者是union（必要的时候）的方式来代替“or”会得到更好的效果。7. 尽量用union all代替unionunion和unionall的差异主要是前者需要将结果集合并后再进行唯一性过滤操作，这就会涉及到排序，增加大量的CPU运算，加大资源消耗及延迟。当然，union all的前提条件是两个结果集没有重复数据。8. 不使用ORDER BY RAND()1select id from `dynamic` order by rand() limit 1000; 上面的SQL语句，可优化为： 1select id from `dynamic` t1 join (select rand() * (select max(id) from `dynamic`) as nid) t2 on t1.id &gt; t2.nidlimit 1000; 9. 区分in和exists、not in和not exists1select * from 表A where id in (select id from 表B) 上面SQL语句相当于 1select * from 表A where exists(select * from 表B where 表B.id=表A.id) 区分in和exists主要是造成了驱动顺序的改变（这是性能变化的关键），如果是exists，那么以外层表为驱动表，先被访问，如果是IN，那么先执行子查询。所以IN适合于外表大而内表小的情况；EXISTS适合于外表小而内表大的情况。 关于not in和not exists，推荐使用not exists，不仅仅是效率问题，not in可能存在逻辑问题。如何高效的写出一个替代not exists的SQL语句？原SQL语句： 1select colname … from A表 where a.id not in (select b.id from B表) 高效的SQL语句： 1select colname … from A表 Left join B表 on where a.id = b.id where b.id is null 取出的数据集是A表不在B表中的数据。A - ( A ∩ B)。 10. 使用合理的分页方式以提高分页的效率1select id,name from product limit 866613,20; 使用上述SQL语句做分页的时候，可能有人会发现，随着表数据量的增加，直接使用limit分页查询会越来越慢。优化的方法如下：可以取前一页的最大行数的id，然后根据这个最大的id来限制下一页的起点。比如此列中，上一页最大的id是866612。SQL可以采用如下的写法： 1select id,name from product where id&gt; 866612 limit 20 11. 分段查询在一些用户选择页面中，可能一些用户选择的时间范围过大，造成查询缓慢。主要的原因是扫描行数过多。这个时候可以通过程序，分段进行查询，循环遍历，将结果合并处理进行展示。扫描的行数成百万级以上的时候就可以使用分段查询： 12. 避免在where子句中对字段进行null值判断对于null的判断会导致引擎放弃使用索引而进行全表扫描。 13. 不建议使用%前缀模糊查询例如 LIKE“%name” 或者 LIKE“%name%” ，这种查询会导致索引失效而进行全表扫描。但是可以使用LIKE “name%”。那如何查询%name%？答案：使用全文索引。在我们查询中经常会用到select id,fnum,fdst from dynamic_201606 where user_name like ‘%zhangsan%’; 。这样的语句，普通索引是无法满足查询需求的。庆幸的是在MySQL中，有全文索引来帮助我们。创建全文索引的SQL语法是： 1ALTER TABLE `dynamic_201606` ADD FULLTEXT INDEX `idx_user_name` (`user_name`); 使用全文索引的SQL语句是： 1select id,fnum,fdst from dynamic_201606 where match(user_name) against(&apos;zhangsan&apos; in boolean mode); 注意：在需要创建全文索引之前，请联系DBA确定能否创建。同时需要注意的是查询语句的写法与普通索引的区别。 14. 避免在where子句中对字段进行表达式操作比如： 1select user_id,user_project from user_base where age*2=36; 中对字段就行了算术运算，这会造成引擎放弃使用索引，建议改成： 1select user_id,user_project from user_base where age=36/2; 15. 避免隐式类型转换where子句中出现column字段的类型和传入的参数类型不一致的时候发生的类型转换，建议先确定where中的参数类型。 16. 对于联合索引来说，要遵守最左前缀法则举列来说索引含有字段id、name、school，可以直接用id字段，也可以id、name这样的顺序，但是name;school都无法使用这个索引。所以在创建联合索引的时候一定要注意索引字段顺序，常用的查询字段放在最前面。 17. 必要时可以使用force index来强制查询走某个索引有的时候MySQL优化器采取它认为合适的索引来检索SQL语句，但是可能它所采用的索引并不是我们想要的。这时就可以采用forceindex来强制优化器使用我们制定的索引。 18. 注意范围查询语句对于联合索引来说，如果存在范围查询，比如between、&gt;、&lt;等条件时，会造成后面的索引字段失效。 19. 关于JOIN优化LEFT JOIN A表为驱动表，INNER JOIN MySQL会自动找出那个数据少的表作用驱动表，RIGHT JOIN B表为驱动表。注意： MySQL中没有full join，可以用以下方式来解决： 1select * from A left join B on B.name = A.namewhere B.name is nullunion allselect * from B; 尽量使用inner join，避免left join：参与联合查询的表至少为2张表，一般都存在大小之分。如果连接方式是inner join，在没有其他过滤条件的情况下MySQL会自动选择小表作为驱动表，但是left join在驱动表的选择上遵循的是左边驱动右边的原则，即left join左边的表名为驱动表。 合理利用索引：被驱动表的索引字段作为on的限制字段。 利用小表去驱动大表：如果能够减少驱动表的话，减少嵌套循环中的循环次数，以减少 IO总量及CPU运算的次数。 巧用STRAIGHT_JOIN：inner join是由MySQL选择驱动表，但是有些特殊情况需要选择另个表作为驱动表，比如有group by、order by等「Using filesort」、「Using temporary」时。STRAIGHT_JOIN来强制连接顺序，在STRAIGHT_JOIN左边的表名就是驱动表，右边则是被驱动表。在使用STRAIGHT_JOIN有个前提条件是该查询是内连接，也就是inner join。其他链接不推荐使用STRAIGHT_JOIN，否则可能造成查询结果不准确。 转载总结自网络。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>myql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL中的控制流程函数]]></title>
    <url>%2F2017%2F11%2F18%2F1%2F</url>
    <content type="text"><![CDATA[控制流程函数 CASE value WHEN [compare-value] THEN result [WHEN [compare-value] THEN result …] [ELSE result] END返回当 value = compare-value 的 result CASE WHEN [condition] THEN result [WHEN [condition] THEN result …] [ELSE result] END当第一个为真值的condition出现时，返回该条件的结果，如果没有匹配的结果值，那么else后的结果将被返回，如果没有else部分，那么返回NULL。 123456mysql&gt; SELECT CASE 1 WHEN 1 THEN &apos;one&apos; WHEN 2 THEN &apos;two&apos; ELSE &apos;more&apos; END; -&gt;&quot;one&quot; mysql&gt; SELECT CASE WHEN 1&gt;0 THEN &apos;true&apos; ELSE &apos;false&apos; END; -&gt;&quot;true&quot;mysql&gt; SELECT CASE BINARY &apos;B&apos; WHEN &apos;a&apos; THEN 1 WHEN &apos;b&apos; THEN 2 END; -&gt;NULL 一个 CASE 表达式的默认返回值类型是任何返回值的兼容类型，但具体情况视其所在语境而定。如果用在字符串语境中，则返回结果为字符串类型。如果用在数字语境中，则返回结果为十进制值、实数值或整数值。 IF(expr1,expr2,expr3)如果expr1是TRUE(expr1 &lt;&gt; 0 and expr1 &lt;&gt; NULL)，则IF()的返回值为expr2; 否则返回值则为expr3。IF()的返回值是否为数字值或字符串值，具体情况视其所在语境而定。123456mysql&gt; SELECT IF(1&gt;2,2,3); -&gt;&quot;3&quot;mysql&gt; SELECT IF(1&lt;2,&apos;yes &apos;,&apos;no&apos;); -&gt;&quot;yes&quot;mysql&gt; SELECT IF(STRCMP(&apos;test&apos;,&apos;test1&apos;),&apos;no&apos;,&apos;yes&apos;); -&gt;&quot;no&quot; 注：STRCMP(expr1,expr2) 如果字符串相同，则STRCMP（）返回0;如果第一个参数根据当前排序顺序小于第二个参数，则返回-1，否则返回1。 如果expr2或expr3中只有一个表达式是NULL值，则IF()函数的结果类型 为非NULL表达式的结果类型。expr1必须作为一个整数值进行评估，也就是说，假如你正在验证浮点值或字符串值，那么应该使用比较运算进行检验。 1234mysql&gt; SELECT IF(0.1,1,0); -&gt; 1mysql&gt; SELECT IF(0.1&lt;&gt;0,1,0); -&gt; 1 观察并对比上述语句的返回结果，发现在上述的第一个例子中，IF(0.1)的返回值为1，原因是IF(0.1)检验为真。在第二个例子中，比较检验了原始浮点值，目的是为了了解是否其为非零值，对比的结果是0.1确实不等于0，那么第一个表达式的结果就是整数1，因此返回结果为1。 IF()（这一点在其被储存到临时表时很重要）的默认返回值类型按照以下方式计算： 表达式 返回值 expr2 或 expr3 返回值为一个字符串 字符串 expr2 或 expr3 返回值为一个整数 整数 expr2 或 expr3 返回值为一个浮点值 浮点值 假如expr2和expr3都是字符串类型，且其中任何一个字符串区分大小写，则返回结果都是区分大小写。 IFNULL(expr1,expr2)假如expr1不为NULL，则 IFNULL() 的返回值为 expr1；否则其返回值为expr2。IFNULL() 的返回值是否为数字或是字符串，具体情况取决于其所使用的语境。123456mysql&gt; SELECT IFNULL(1,0); -&gt; 1mysql&gt; SELECT IFNULL(NULL,10); -&gt; 10mysql&gt; SELECT IFNULL(1/0,10); -&gt; 10.000 IFNULL(expr1,expr2)的默认结果值为两个表达式中数据类型更加“通用”的一个，顺序为STRING、REAL或 INTEGER。假设有一个表中含有该表达式，或 MySQL 必须在内存储器中储存 IFNULL() 的返回值到一个临时表中： 12CREATE TABLE tmp SELECT IFNULL(1,&apos;test&apos;) AS test；DESCRIBE tmp; 在这个例子中，测试列的类型为字符串类型CHAR(4)。 NULLIF(expr1,expr2)如果expr1 = expr2成立，那么返回值为NULL，否则返回值为expr1。这和CASE WHEN expr1 = expr2 THEN NULL ELSE expr1 END语句的原理相同。1234mysql&gt; SELECT NULLIF(1,1); -&gt; NULLmysql&gt; SELECT NULLIF(1,2); -&gt; 2 注意：如果参数不相等，则 MySQL 会评估expr1两次。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL比较函数和操作符]]></title>
    <url>%2F2017%2F11%2F17%2F1%2F</url>
    <content type="text"><![CDATA[MySQL 按照以下规则进行数值比较：本文转载自实验楼,同学们可以在实验楼《Mysql基础教程中》学习。 若函数中有一个或两个参数都是NULL，则比较运算的结果为NULL，除非是等号比较运算符&lt;=&gt;。 若同一个比较运算中的两个参数都是字符串类型，则作为字符串进行比较。 若两个参数均为整数，则按照整数进行比较。 十六进制值在不作为数字进行比较时，则按照二进制字符串处理。 假如参数中的一个为 TIMESTAMP 或 DATETIME + 数据类型，而其它参数均为常数，则在进行比较前应该将常数转为 timestamp 类型。这样做的目的是为了使 ODBC 的进行更加顺利。注意： 这不用于 IN() 中的参数 ! 为了更加可靠，在进行对比时通常使用完整的datetime/date/time字符串。 在其它情况下，参数作为浮点数（实数）进行比较。 在默认状态下，字符串比较不区分大小写，并使用现有字符集(默认为 cp1252 Latin1，同时也适用于英语)。为了达到比较的目的，可使用 CAST() 函数将某个值转为另外一种类型。使用 CONVERT() 可以将字符串值转为不同的字符集。 下面对各类操作符的使用进行示例 #后为语句答案： =等于：123mysql&gt; SELECT 1 = 0; # 0mysql&gt; SELECT &apos;0&apos; = 0; # 1mysql&gt; SELECT &apos;0.01&apos; = 0; # 0 对于行比较，(a, b) = (x, y)相当于：(a = x) AND (b = y)。 &lt;=&gt; 空值安全的等号： 这个操作符与 = 操作符执行相同的比较操作，不过在两个操作码均为 NULL 时，其返回至为 1 而不为 NULL，而当一个操作码为 NULL 时，其所得值为 0 而不为 NULL。 12mysql&gt; SELECT 1 &lt;=&gt; 1, NULL &lt;=&gt; NULL, 1 &lt;=&gt; NULL; # 1 1 0mysql&gt; SELECT 1 = 1, NULL = NULL, 1 = NULL; # 1 NULL NULL 对于行比较，(a, b) &lt;=&gt; (x, y)相当于：(a &lt;=&gt; x) AND (b &lt;=&gt; y)。 &lt;&gt; 或 != 不等于：123mysql&gt; SELECT &apos;.01&apos; &lt;&gt; &apos;0.01&apos;; # 1mysql&gt; SELECT .01 &lt;&gt; &apos;0.01&apos;; # 0myql&gt; SELECT &apos;zapp&apos; &lt;&gt; &apos;zappp&apos;; # 1 对于行比较，(a, b) &lt;&gt; (x, y)相当于：(a &lt;&gt; x) OR (b &lt;&gt; y)。 &lt;= 小于等于：1mysql&gt; SELECT 0.1 &lt;= 2; # 1 对于行比较，(a, b) &lt;= (x, y)相当于：(a &lt;= x) AND (b &lt;= y)。 大于： 1mysql&gt; SELECT 2 &gt; 2; #1 对于行比较，(a, b) &gt; (x, y)相当于：(a &gt; x) AND (b &gt; y)。 IS boolean_value 和 IS NOT boolean_value：根据一个布尔值来检验一个值，在这里，布尔值可以是 TRUE、FALSE 或 UNKNOWN。 12345mysql&gt; SELECT 1 IS TRUE, 0 IS FALSE, NULL IS UNKNOWN; # 1 1 1mysql&gt; SELECT 1 IS NOT UNKNOWN, 0 IS NOT UNKNOWN, NULL IS NOT UNKNOWN; # 1 1 0mysql&gt; SELECT 1 IS NULL, 0 IS NULL, NULL IS NULL; # 0 0 1mysql&gt; SELECT 1 IS NOT NULL, 0 IS NOT NULL, NULL IS NOT NULL; # 1 1 0 expr BETWEEN min AND max 假如 expr 大于或等于 min 且 expr 小于或等于 max, 则 BETWEEN 的返回值为 1，否则是 0。若所有参数都是同一类型，则上述关系相当于表达式 ： min &lt;= expr AND expr &lt;= max。其它类型的转换 根据本章开篇所述规律进行，且适用于 3 种参数中任意一种。 123mysql&gt; SELECT 1 BETWEEN 2 AND 3; # 0mysql&gt; SELECT &apos;b&apos; BETWEEN &apos;a&apos; AND &apos;c&apos;; # 1mysql&gt; SELECT 2 BETWEEN 2 AND &apos;3&apos;; # 1 expr NOT BETWEEN min AND max 这相当于 NOT(expr BETWEEN min AND max)。 COALESCE(value,…) 返回参数列表当中的第一个非 NULL 值，在没有非 NULL 值的情况下返回值为NULL。 12mysql&gt; SELECT COALESCE(NULL,1); # 1mysql&gt; SELECT COALESCE(NULL,NULL,NULL); # NULL GREATEST(value1,value2,…) 当有2个或2个以上参数时，返回值为最大(最大值的)参数。比较参数所依据的规律同LEAST()相同。 12mysql&gt; SELECT GREATEST(2,0); # 2mysql&gt; SELECT GREATEST(&apos;B&apos;,&apos;A&apos;,&apos;C&apos;); # C 在所有参数为NULL的情况下，GREATEST()的返回值为NULL。 expr IN (value,…)若expr为IN列表中的任意一个值，则其返回值为1, 否则返回值为0。假如所有的值都是常数，则其计算和分类根据 expr的类型进行。这时，使用二分搜索来搜索信息。如果IN值列表全部由常数组成，则意味着IN的速度非常快。如果expr是一个区分大小写的字符串表达式，则字符串比较也按照区分大小写的方式进行。12mysql&gt; SELECT 2 IN (0,3,5,&apos;wefwf&apos;); # 0mysql&gt; SELECT &apos;wefwf&apos; IN (0,3,5,&apos;wefwf&apos;); # 1 IN列表中所列值的个数仅受限于max_allowed_packet值。为了同SQL标准相一致，在左侧表达式为NULL的情况下，或是表中找不到匹配项或是表中一个表达式为NULL的情况下，IN的返回值均为NULL。 ()语法也可用于书写某些类型的子查询。 expr NOT IN (value,…)这与NOT (expr IN (value,…))相同。ISNULL(expr)如果expr为NULL，那么ISNULL()的返回值为1，否则返回值为0。 12mysql&gt; SELECT ISNULL(1+1); # 0mysql&gt; SELECT ISNULL(1/0); # 1 通常使用ISNULL()来判断一个值是否为NULL。（使用=比较符对比一个值与NULL值是错误的）。 INTERVAL(N,N1,N2,N3,…)假如N &lt; N1，则返回值为0；假如N &lt; N2 等，则返回值为1；假如N为NULL，则返回值为-1。所有的参数均按照整数处理。为了这个函数的正确运行，必须满足N1 &lt; N2 &lt; N3 &lt; ……&lt; Nn 。其原因是使用了二分查找。123mysql&gt; SELECT INTERVAL(23, 1, 15, 17, 30, 44, 200); # 3mysql&gt; SELECT INTERVAL(10, 1, 10, 100, 1000); # 2mysql&gt; SELECT INTERVAL(22, 23, 30, 44, 200); # 1]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL基础操作补充]]></title>
    <url>%2F2017%2F11%2F16%2F1%2F</url>
    <content type="text"><![CDATA[1. LAST_INSERT_ID()自动返回最后一个INSERT或 UPDATE 问询为 AUTO_INCREMENT列设置的第一个 发生的值。 1mysql&gt; SELECT LAST_INSERT_ID(） 产生的ID 每次连接后保存在服务器中。这意味着函数向一个给定客户端返回的值是该客户端产生对影响AUTO_INCREMENT列的最新语句第一个 AUTO_INCREMENT值的。这个值不能被其它客户端影响，即使它们产生它们自己的 AUTO_INCREMENT值。这个行为保证了你能够找回自己的 ID 而不用担心其它客户端的活动，而且不需要加锁或处理。（因为last_insert_id是针对connection的）假如你使用一个非“magic”值来更新某一行的AUTO_INCREMENT 列，则LAST_INSERT_ID() 的值不会变化(换言之, 一个不是 NULL也不是 0的值)。重点: 假如你使用单INSERT语句插入多个行， LAST_INSERT_ID() 只返回插入的第一行产生的值。其原因是这使依靠其它服务器复制同样的 INSERT语句变得简单。 2。 Mysql删除数据后更新自增idalter table table_name AUTO_INCREMENT=n 3. 计算每月的访问量下面使用BIT_COUNT函数计算每个月中某用户访问网页的天数： 12CREATE TABLE t1 (year YEAR(4), month INT(2) UNSIGNED ZEROFILL,day INT(2) UNSIGNED ZEROFILL);INSERT INTO t1 VALUES(2000,1,1),(2000,1,20),(2000,1,30),(2000,2,2),(2000,2,23),(2000,2,23); 上述建立的表中有用户访问网页的年月日，可以使用以下语句查询每个月的访问天数： 1SELECT year,month,BIT_COUNT(BIT_OR(1&lt;&lt;day)) AS days FROM t1 GROUP BY year,month;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL中用户变量和系统变量]]></title>
    <url>%2F2017%2F11%2F16%2F1%2F</url>
    <content type="text"><![CDATA[1. MYSQL中的用户变量和系统变量1.1 用户变量可以先在用户变量中保存值然后在以后引用它；这样可以将值从一个语句传递到另一个语句。用户变量与连接有关。也就是说，一个客户端定义的变量不能被其它客户端看到或使用。当客户端退出时，该客户端连接的所有变量将自动释放。用户变量的形式为@var_name，其中变量名var_name可以由当前字符集的文字数字字符、‘.’、‘_’和‘$’组成。 默认字符集是cp1252 (Latin1)。可以用mysqld的–default-character-set选项更改字符集，用户变量名对大小写不敏感。设置用户变量的两种语句形式 12SET @var_name = expr [, @var_name = expr] ...SELECT @var_name := expr [, @var_name = expr] ... 对于 SET，可以使用=或:=作为分配符。分配给每个变量的expr可以为整数、实数、字符串或者NULL值。对于 SELECR，分配符必须为:=而不能用=，因为在非SET语句中=被视为一个比较 操作符。注: 在 SELECT 语句中，表达式发送到客户端后才进行计算。这说明在 HAVING、GROUP BY 或者 ORDER BY 子句中，不能使用包含 SELECT 列表中所设的变量的表达式。 1.2 系统变量MySQL可以访问许多系统和连接变量。当服务器运行时许多变量可以动态更改。这样通常允许你修改服务器操作而不需要停止并重启服务器。 mysqld服务器维护两种变量。全局变量影响服务器整体操作。会话变量影响具体客户端连接的操作。 当服务器启动时，它将所有全局变量初始化为默认值。这些默认值可以在选项文件中或在命令行中指定的选项进行更改。服务器启动后，通过连接服务器并执行SET GLOBAL var_name语句，可以动态更改这些全局变量。要想更改全局变量，必须具有SUPER权限。 服务器还为每个连接的客户端维护一系列会话变量。在连接时使用相应全局变量的当前值对客户端的会话变量进行初始化。对于动态会话变量，客户端可以通过SET SESSION var_name语句更改它们。设置会话变量不需要特殊权限，但客户端只能更改自己的会话变量，而不能更改其它客户端的会话变量。 对于全局变量的更改可以被访问该全局变量的任何客户端看见。然而，它只影响更改后连接的客户的从该全局变量初始化的相应会话变量。不影响目前已经连接的客户端的会话变量(即使客户端执行SET GLOBAL语句也不影响)。 可以使用几种语法形式来设置或检索全局或会话变量。下面的例子使用了sort_buffer_sizeas作为示例变量名。要想设置一个GLOBAL变量的值，使用下面的语法： 12mysql&gt; SET GLOBAL sort_buffer_size=value;mysql&gt; SET @@global.sort_buffer_size=value; 要想设置一个SESSION变量的值，使用下面的语法： 123mysql&gt; SET SESSION sort_buffer_size=value;mysql&gt; SET @@session.sort_buffer_size=value;mysql&gt; SET sort_buffer_size=value; LOCAL是SESSION的同义词。 如果设置变量时不指定GLOBAL、SESSION或者LOCAL，默认使用SESSION。要想检索一个GLOBAL变量的值，使用下面的语法： 12mysql&gt; SELECT @@global.sort_buffer_size;mysql&gt; SHOW GLOBAL VARIABLES like &apos;sort_buffer_size&apos;; 要想检索一个SESSION变量的值，使用下面的语法： 123mysql&gt; SELECT @@sort_buffer_size;mysql&gt; SELECT @@session.sort_buffer_size;mysql&gt; SHOW SESSION VARIABLES like &apos;sort_buffer_size&apos;; 这里，LOCAL也是SESSION的同义词。当你用SELECT @@var_name搜索一个变量时(也就是说，不指定global.、session.或者local.)，MySQL返回SESSION值（如果存在），否则返回GLOBAL值。对于SHOW VARIABLES，如果不指定GLOBAL、SESSION或者LOCAL，MySQL返回SESSION值。当设置GLOBAL变量需要GLOBAL关键字但检索时不需要它们的原因是防止将来出现问题。如果我们移除一个与某个GLOBAL变量具有相同名字的SESSION变量，具有SUPER权限的客户可能会意外地更改GLOBAL变量而不是它自己的连接的SESSION变量。如果我们添加一个与某个GLOBAL变量具有相同名字的SESSION变量，想更改GLOBAL变量的客户可能会发现只有自己的SESSION变量被更改]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql中的DELIMITER详解]]></title>
    <url>%2F2017%2F11%2F16%2F1%2F</url>
    <content type="text"><![CDATA[MYSQL中的delimiter详解命令行客户端中，如果有一行命令以分号结束，那么回车后，mysql将会执行该命令。如输入下面的语句mysql&gt; select * from test_table;然后回车，那么MySQL将立即执行该语句。但有时候，不希望MySQL这么做。在为可能输入较多的语句，且语句中包含有分号。如下： 12345678910111213141516171819202122232425262728CREATE DATABASE test_db;USE test_db;CREATE TABLE test1(a1 INT);CREATE TABLE test2(a2 INT);CREATE TABLE test3(a3 INT NOT NULL AUTO_INCREMENT PRIMARY KEY);CREATE TABLE test4( a4 INT NOT NULL AUTO_INCREMENT PRIMARY KEY, b4 INT DEFAULT 0);DELIMITER |CREATE TRIGGER testref BEFORE INSERT ON test1 FOR EACH ROW BEGIN INSERT INTO test2 SET a2 = NEW.a1; DELETE FROM test3 WHERE a3 = NEW.a1; UPDATE test4 SET b4 = b4 + 1 WHERE a4 = NEW.a1; END|DELIMITER ;INSERT INTO test3 (a3) VALUES (NULL), (NULL), (NULL), (NULL), (NULL), (NULL), (NULL), (NULL), (NULL), (NULL);INSERT INTO test4 (a4) VALUES (0), (0), (0), (0), (0), (0), (0), (0), (0), (0); 上面就是，先将分隔符设置为 |直到遇到下一个 |,才整体执行语句。执行完后，我们使用 delimiter ; 将mysql的分隔符重新设置为分号；如果不修改，本次会话都会以 | 结束运行。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL基础操作总结（二）]]></title>
    <url>%2F2017%2F11%2F15%2F1%2F</url>
    <content type="text"><![CDATA[1. 数据库表的修改以及删除删除数据库 1DROP DATABASE &lt;数据库名字&gt;; 删除数据库中的表 1DROP TABLE &lt;表名字&gt;; 修改表的名字 1RENAME TABLE &lt;原名&gt; TO &lt;新名字&gt;; 表中新增加一列 1ALTER TABLE &lt;表名字&gt; ADD &lt;列名字&gt; &lt;数据类型&gt; &lt;约束&gt;; 具体增加到某一列后边使用after关键字 1ALTER TABLE &lt;表名字&gt; ADD &lt;列名字&gt; &lt;数据类型&gt; &lt;约束&gt; after &lt;某一列&gt;; 增加第一列后边使用first关键字 1ALTER TABLE &lt;表名字&gt; ADD &lt;列名字&gt; &lt;数据类型&gt; &lt;约束&gt; first; 修改数据类型 1ALTER TABLE &lt;表名字&gt; MODIFY &lt;列名字&gt; &lt;新数据类型&gt;; 修改表中某个值 1UPDATE &lt;表名字&gt; SET &lt;列1=值1&gt;,&lt;列2=值2&gt; WHERE &lt;条件&gt;; 删除一行记录 1DELETE FROM &lt;表名字&gt; WHERE &lt;条件&gt;; 2. 其他基本操作视图：视图是从一个或多个表中导出来的表，是一种虚拟存在的表。它就像一个窗口，通过这个窗口可以看到系统专门提供的数据，这样，用户可以不用看到整个数据库中的数据，而只关心对自己有用的数据。创建视图 1CREATE VIEW &lt;视图名(列a,列b,列c)&gt; AS SELECT &lt;列1&gt;,&lt;列2&gt;,&lt;列3&gt; FROM &lt;表名字&gt; where &lt;条件&gt;; 纯数据文件导入：文件中将包含与数据表字段相对应的多条数据，这样可以快速导入大量数据。 1LOAD DATA INFILE &lt;文件路径和文件名&gt; INTO TABLE &lt;表名字&gt;; 注：由于导入导出大量数据都属于敏感操作，根据 mysql 的安全策略，导入导出的文件都必须在指定的路径下进行，在 mysql 终端中查看路径变量： 1show variables like &apos;%secure%&apos;; SQL 语句导入，语法为：source *.sql不同点：数据文件导入方式只包含数据，导入规则由数据库系统完成；SQL 文件导入相当于执行该文件中包含的 SQL 语句，可以实现多种操作，包括删除，更新，新增，甚至对数据库的重建。导出:与导入是相反的过程，是把数据库某个表中的数据保存到一个文件之中。导出语句基本格式为： 1SELECT 列1，列2 INTO OUTFILE &apos;文件路径和文件名&apos; FROM 表名字; 数据库备份 12mysqldump -u root 数据库名&gt;备份文件名; #备份整个数据库mysqldump -u root 数据库名 表名字&gt;备份文件名; #备份整个表 注：是在终端进行备份，不是在mysql中。数据库恢复第一种方法 123source \*.sql ``` **数据库恢复第二种方法** CREATE DATABASE shujuku; #新建一个名为shujuku的数据库 #再次 Ctrl+D 退出 MySQL：mysql -u root shujuku &lt; bak.sql #数据恢复到shujuku数据库 ## 3. 补充 还有一部分关于子查询，连接查询的，建议大家阅读这个博客[mysql子查询](https://www.cnblogs.com/chiangchou/p/mysql-3.html)]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL问题记录]]></title>
    <url>%2F2017%2F11%2F14%2F1%2F</url>
    <content type="text"><![CDATA[记录一个蠢蠢的问题在导入数据集的时候发现了如下一个error 1ERROR 1406 (22001): Data too long for column Google了好久，在 stackoverflow 找到了一个靠谱的答案，如下：暗自开心的按照教程改了一，结果完全没用，又走上了漫长的谷歌道路，改字符编码啊等等……吃饭的时候脑子闪过一个念头会不会是编辑器的问题啊。 在排查的过程中果然是，在vim下编辑会因为配置问题把TAB全部转换了成空格，mysql分隔符使用的是“TAB”,自然就报错。最后在补充一个知识点可以使用 FIELDS TERMINATED BY LINES TERMINATED BY关键字进行导入数据]]></content>
      <categories>
        <category>问题随笔</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL基础操作总结（一）]]></title>
    <url>%2F2017%2F11%2F13%2F1%2F</url>
    <content type="text"><![CDATA[本文是对mysql基础操作的一个简单总结，同学们，可以点击这个链接在线实战。实验楼mysql基础教程在开始之前，例如其他编程语言一样,mysql同样有自己的数据类型,建议大家可以阅读这篇文章mysql数据类型 1. 创建并使用数据库创建数据库 1CREATE DATABASE &lt;数据库名字&gt;; 由于一个系统中可能会有多个数据库，要确定当前是对哪一个数据库操作，使用语句 123use &lt;数据库名字&gt;;&gt; 段落引用 查看当前数据库里有几张表 1show tables; 数据表示是数据库最重要的组成部分之一。一个数据库中一般会有多张表，这些各自独立的表通过建立关系被联接起来，才成为可以数据库。如下便是一张表：| 项目 | 价格 | 数量 || :——: | :—-: | :—-: || 01 | xiaoma | 110 || 02 | xiaohu | 112 || 03 | xiaozhang | 123 |在数据库中新建一张表的语句格式为： 123456CREATE TABLE 表的名字(列名a 数据类型(数据长度),列名b 数据类型(数据长度)，列名c 数据类型(数据长度)); 查看新建表中的内容 1SELECT * FROM &lt;数据表的名字&gt;; 使用语句向表中插入数据 1INSERT INTO 表的名字(列名a,列名b,列名c) VALUES(值1,值2,值3); 2. mysql的约束约束是一种限制，通过对表的行或列做出数据限制，来确保数据的完整性，唯一性等。 2.1 约束的种类 主键 PRIMARY KEY 默认值 DEFAULT 唯一 UNIQUE 外键 FOREIGN KEY 非空 NOT NULL2.1.1 主键约束主键 (PRIMARY KEY)是用于约束表中的一行，作为这一行的唯一标识符，在一张表中通过主键就能准确定位到一行，因此主键十分重要，主键不能有重复记录且不能为空。给某个字段添加主键约束之后，该字段不能重复也不能为空，效果和”not nullunique”约束相同，但是本质不同。主键约束除了可以做到”not null unique”之外，还会默认添加”索引”2.1.2 默认值约束DEFAULT 约束只会在使用 INSERT 语句（上一实验介绍过）时体现出来， INSERT 语句中，如果被 DEFAULT 约束的位置没有值，那么这个位置将会被 DEFAULT 的值填充。使用场景:默认值经常会使用在一些可有可无的字段，比如个性签名中，如果没有数据就会默认为空或者一个默认的文本2.1.2 唯一约束唯一约束 (UNIQUE) 比较简单，它规定一张表中指定的一列的值必须不能有重复值，即这一列每个值都是唯一的。2.1.3 外键约束若有两个表A、B，id是A的主键，而B中也有id字段，则id就是表B的外键，外键约束主要用来维护两个表之间数据的一致性。一个表可以有多个外键，每个外键必须 REFERENCES(参考)另一个表的主键，被外键约束的列，取值必须在它参考的列中有对应值1foreign key&lt;classno)&gt; references t_class(cno) 上述就表示当前表中字段 classno 是和表 t_class 中字段 cno 保持一致。 2.1.4 非空约束非空约束 (NOT NULL),听名字就能理解，被非空约束的列，在插入值时必须非空。 3. 查询语句SELECT语句的基本格式 1234SELECT column_name,column_nameFROM table_name[WHERE Clause][LIMIT N][ OFFSET M] 使用一个或者多个表，表之间使用逗号(,)分割，并使用WHERE语句来设定查询条件。 SELECT 命令可以读取一条或者多条记录。 使用星号（*）来代替其他字段，SELECT语句会返回表的所有字段数据 使用 WHERE 语句来包含任何条件。 使用 LIMIT 属性来设定返回的记录数。 通过OFFSET指定SELECT语句开始查询的数据偏移量。默认情况下偏移量为0。where语句其中where语句后边就和我们经常编程使用的if条件语句一样。这里只总结一下: 数学符号条件：=,&lt;,&gt;,&gt;=,&lt;= “AND 与 OR” “IN 与 NOT IN”通配符在这里详细介绍一下通配符通配符语句的基本格式1WHERE column_name LIKE &apos;通配符号&apos;; %：表示任意0个或多个字符。如下，既可以查出 “s”，“stt”，“sxxx”等 1WHERE column_name LIKE &apos;s%&apos;; _ ： 表示任意单个字符。匹配单个任意字符，它常用来限制表达式的字符长度语句：如下，只能查出S后边带两个字符的项 1WHERE column_name LIKE &apos;s__&apos;; [字符列] ：字符列中任何一个单一字符[^字符列] 或者[!字符列]: 不在字符列中的任何一个单一字符除了上边介绍的like进行mysql模糊查询外，还有一种正则表达式模糊查询 必须使用regexp关键字。mysql中正则表达式模糊查询使用格式结果排序ORDER BY 排序关键词。默认情况下，ORDER BY 的结果是升序排列，而使用关键词 ASC 和 DESC 可指定升序或降序排序。语句格式如下 1SELECT column_name,column_name,e FROM table ORDER BY column_name DESC;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu下mysql的安装问题总结]]></title>
    <url>%2F2017%2F11%2F12%2F1%2F</url>
    <content type="text"><![CDATA[1. mysql的安装 系统：Ubuntu Server 16.04.1 LTS 64位 1234#安装 MySQL 服务端sudo apt-get install mysql-server#安装 MySQL 客户端sudo apt-get install mysql-client 安装过程中自己设置root密码 12#查看是否安装成功sudo netstat -tap | grep mysql 查看是否安装成功，如果出现如下提示，则安装成功 12ubuntu@VM-0-11-ubuntu:~$ sudo netstat -tap | grep mysqltcp 0 0 localhost.localdo:mysql *:* LISTEN 25092/mysqld 使用如下两条命令，打开 MySQL 服务并使用 root 用户登录： 1234# 启动 MySQL 服务sudo service mysql start# 使用 root 用户登录，实验楼环境的密码为空，直接回车就可以登录mysql -uroot -p 在安装过程会提示输入密码，但是输入的密码没有作用，并且出现如下的错误，我把自己怎么改的教程直接贴出来，照着我的改然后重新登录就可以了。 错误:&emsp;ERROR 1045 (28000): Access denied for user &#39;root&#39;@&#39;localhost&#39; 1234567891011121314151617181920212223#使用sudo cat /etc/mysql/debian.cnf查看用户名密码ubuntu@VM-0-11-ubuntu:~$ sudo cat /etc/mysql/debian.cnf [client]host = localhostuser = debin-sys-matpassword = he5gNV6mzFoxQcsocket = /var/run/mysqld/mysqld.sock[mysql_upgrade]host = localhostuser = debin-sys-matpassword = he5gNV6mzFoxQcsocket = /var/run/mysqld/mysqld.sock用户以及密码#出现的user=debin-sys-mat是用户名，password = he5gNV6mzFoxQc为密码#用查询到的用户名以及密码登陆mysql -udebin-sys-mat -phe5gNV6mzFoxQc#注意用户名和密码之前分别有 -u和-p#用下边命令改root密码update user set authentication_string=password(&apos;要改的密码&apos;) where user=&quot;root&quot;;#mysql 新设置用户或更改密码后需用flush privileges刷新MySQL的系统权限相关表，否则会出现拒绝访问。flush privileges; 这样就安装好并且可以使用mysql。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pip修改默认镜像源]]></title>
    <url>%2F2017%2F11%2F02%2F1%2F</url>
    <content type="text"><![CDATA[windows10 下 python 用 pip 安装报错 解决方法：修改默认镜像源 在windows文件管理器中,输入 %APPDATA% 在该目录下新建 pip 文件 在新建的 pip 文件下创建 pip.ini 并输入以下内容:[global] timeout = 6000 index-url = http://mirrors.aliyun.com/pypi/simple]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
</search>
